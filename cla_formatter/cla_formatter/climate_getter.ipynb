{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00e9f0d-3a9d-4686-8a8f-ba74bfb3e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os, sys\n",
    "import itertools\n",
    "from datetime import datetime, timezone\n",
    "import calendar\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import textwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c16e58-8ed8-43db-ad52-75cebbd48e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed97bdd-82fc-4a0d-849d-ae45947d7f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c20b7d9-6ac0-49e1-bf1d-2fa27325a3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'53'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_timestamp(url):\n",
    "\n",
    "    '''\n",
    "    This function will take a url string, and create a datetime object from the timestamp in the url.\n",
    "\n",
    "    url : str, the API url with the timestamp in the url\n",
    "\n",
    "    returns:\n",
    "    timestamp : a datetime object with the url timestamp\n",
    "    station : str, the three letter station ID\n",
    "\n",
    "    '''\n",
    "    \n",
    "    timestamp = url.split('nwstext/')[-1].split('-KLZK')[0]\n",
    "    \n",
    "    y = timestamp[:4]\n",
    "    m = timestamp[4:6]\n",
    "    d = timestamp[6:8]\n",
    "    hh = timestamp[8:10]\n",
    "    mm = timestamp[10:]\n",
    "\n",
    "    station = url.split('CLM')[-1]\n",
    "    \n",
    "    return datetime(y, m , d, hh, mm), station\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a28a573-34c7-47cf-a121-4b8ed6ea80cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LZK'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.split('CLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7c1b2-5a58-48b1-a261-1492e5e23c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start small, lets set up a script to go query all the monthly products in a single calendar year..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4800710a-fb05-49b7-915a-2b02d8e724c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=02&day=01\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=02&day=02\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=02&day=03\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=02&day=04\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=02&day=05\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLIT\n",
      "  77   01/11         50      27       72  01/13        \n",
      "\n",
      " 25   01/14         31      -6       17  01/22        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLZK\n",
      "  72   01/11         49      23       68  01/01        \n",
      "\n",
      " 24   01/31         31      -7       13  01/21        \n",
      "                       01/14                                           \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMHRO\n",
      "  75   01/02         44      31       66  01/31        \n",
      "\n",
      " 18   01/31         25      -7        3  01/21        \n",
      "                       01/14                                           \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMPBF\n",
      "  77   01/11         50      27       80  01/01        \n",
      "\n",
      " 27   01/14         32      -5       18  01/22        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=03&day=01\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=03&day=02\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=03&day=03\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=03&day=04\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMLIT\n",
      "  81   02/28         56      25       72  02/11        \n",
      "                                                          02/17        \n",
      "\n",
      " 27   02/18         35      -8       23  02/05        \n",
      "                       02/04                                           \n",
      "                                                          02/06        \n",
      "                                                          02/13        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMLZK\n",
      "  79   02/28         55      24       68  02/14        \n",
      "                                                          02/21        \n",
      "\n",
      " 24   02/01         36     -12       22  02/18        \n",
      "                                                          02/04        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMHRO\n",
      "  79   02/28         50      29       71  02/21        \n",
      "\n",
      " 19   02/01         30     -11       13  02/05        \n",
      "                                                          02/18        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMPBF\n",
      "  82   02/28         56      26       76  02/22        \n",
      "\n",
      " 28   02/01         36      -8       22  02/05        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=01\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=02\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=03\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=04\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=05\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=06\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=07\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=04&day=08\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202304081044-KLZK-CXUS54-CLMLIT\n",
      "  83   03/23         64      19       82  03/06        \n",
      "\n",
      " 26   03/20         43     -17       26  03/12        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202304081044-KLZK-CXUS54-CLMLZK\n",
      "  80   03/23         64      16       79  03/03        \n",
      "\n",
      " 26   03/19         45     -19       24  03/12        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202304081044-KLZK-CXUS54-CLMHRO\n",
      "  81   03/31         59      22       80  03/03        \n",
      "\n",
      " 18   03/19         39     -21       15  03/12        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202304081044-KLZK-CXUS54-CLMPBF\n",
      "  83   03/23         65      18       82  03/06        \n",
      "\n",
      " 29   03/20         44     -15       26  03/12        \n",
      "\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=05&day=01\n",
      "https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year=2023&month=05&day=02\n",
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202305021356-KLZK-CXUS54-CLMLIT\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 272\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[38;5;66;03m# set up a timestamp object\u001b[39;00m\n\u001b[0;32m    270\u001b[0m             timestamp \u001b[38;5;241m=\u001b[39m parse_timestamp(y, m, d, hh, mm)\n\u001b[1;32m--> 272\u001b[0m             \u001b[43mtext_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCLM\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstation\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;66;03m#print(\u001b[39;00m\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;66;03m#station_time_dict['product_time'].append(product_time)\u001b[39;00m\n\u001b[0;32m    276\u001b[0m             \u001b[38;5;66;03m#print(station, time)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# exit the for loop for iterating through days and move onto the next month in the parent for loop\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m product_found:\n",
      "Cell \u001b[1;32mIn[3], line 166\u001b[0m, in \u001b[0;36mtext_parser\u001b[1;34m(timestamp, pil)\u001b[0m\n\u001b[0;32m    163\u001b[0m api_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://mesonet.agron.iastate.edu/api/1/nwstext/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mhh\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-KLZK-CXUS54-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpil\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(api_url)\n\u001b[1;32m--> 166\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    167\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# kill all script and style elements\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sounderpy_env\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # ----------------------------------------------------------\n",
    "# def parse_timestamp(y, m, d, hh, mm):\n",
    "\n",
    "#     return datetime(y, m, d, hh, mm)\n",
    "#     #timestamp = timestamp.astimezone()\n",
    "#     #return timestamp.astimezone(timezone.utc)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def count_spaces(line):\n",
    "\n",
    "    # this should be the date in the line\n",
    "    split_date = list(filter(None, (line.split(' '))))[0]\n",
    "\n",
    "    # this is the number of spaces for it to be a date occurred that month\n",
    "    if line.split(split_date)[0].count(' ') < 30:\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# def get_maxmin_data(high_temp_data, low_temp_data, station, month):\n",
    "\n",
    "#     '''\n",
    "#     Worker function to extract high and low data/dates from the CLM products.\n",
    "    \n",
    "#     '''\n",
    "\n",
    "#     month = calendar.month_name[month][:3].upper()\n",
    "    \n",
    "#     # first filter the line of temp data\n",
    "#     filtered_low_temp_data = list(filter(None, low_temp_data.split(' '))) # low temp data\n",
    "#     filtered_high_temp_data = list(filter(None, high_temp_data.split(' '))) # high temp data\n",
    "    \n",
    "#     # lets add the high and low values to the dictionary\n",
    "#     data_dict[station][month]['lows'].append(filtered_low_temp_data[0])\n",
    "#     data_dict[station][month]['highs'].append(filtered_high_temp_data[0])\n",
    "\n",
    "    \n",
    "#     ## LOW TEMP DATA DATES ##\n",
    "#     #---------------------------------------------------------------\n",
    "#     # check how many lines exist in the list\n",
    "#     # if only one line, then just one date to grab\n",
    "#     if len(low_temp_data.splitlines()) == 1:\n",
    "    \n",
    "#         data_dict[station][month]['low_dates'].append([filtered_low_temp_data[1]])\n",
    "    \n",
    "#     # if there are multiple rows of low temp data, then multiple dates to grab\n",
    "#     elif len(low_temp_data.splitlines()) > 1:\n",
    "#         dates = []\n",
    "        \n",
    "#         # grab the first date in the line\n",
    "#         dates.append(filtered_low_temp_data[1])\n",
    "    \n",
    "#         # now iterate and find the rest of the dates\n",
    "#         for line in low_temp_data.splitlines()[1:]:\n",
    "#             if count_spaces(line):\n",
    "#                 dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "    \n",
    "    #     data_dict[station][month]['low_dates'].append(dates)\n",
    "    \n",
    "    \n",
    "    # ## HIGH TEMP DATA DATES ##\n",
    "    # #---------------------------------------------------------------\n",
    "    # # check how many lines exist in the list\n",
    "    # # if only one line, then just one date to grab\n",
    "    # if len(high_temp_data.splitlines()) == 1:\n",
    "    \n",
    "    #     data_dict[station][month]['high_dates'].append([filtered_high_temp_data[1]])\n",
    "    \n",
    "    # # if there are multiple rows of high temp data, then multiple dates to grab\n",
    "    # elif len(high_temp_data.splitlines()) > 1:\n",
    "    #     dates = []\n",
    "        \n",
    "    #     # grab the first date in the line\n",
    "    #     dates.append(filtered_high_temp_data[1])\n",
    "    \n",
    "    #     # now iterate and find the rest of the dates\n",
    "    #     for line in high_temp_data.splitlines()[1:]:\n",
    "    #         if count_spaces(line):\n",
    "    #             dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "    \n",
    "    #     data_dict[station][month]['high_dates'].append(dates)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def text_parser(timestamp, pil):\n",
    "\n",
    "    def get_maxmin_data(high_temp_data, low_temp_data, station, month):\n",
    "    \n",
    "        '''\n",
    "        Worker function to extract high and low data/dates from the CLM products.\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        month = calendar.month_name[month][:3].upper()\n",
    "\n",
    "        print(high_temp_data)\n",
    "        print(low_temp_data)\n",
    "\n",
    "        \n",
    "        # first filter the line of temp data\n",
    "        filtered_low_temp_data = list(filter(None, low_temp_data.split(' '))) # low temp data\n",
    "        filtered_high_temp_data = list(filter(None, high_temp_data.split(' '))) # high temp data\n",
    "        \n",
    "        # lets add the high and low values to the dictionary\n",
    "        data_dict[station][month]['lows'].append(filtered_low_temp_data[0])\n",
    "        data_dict[station][month]['highs'].append(filtered_high_temp_data[0])\n",
    "    \n",
    "        \n",
    "        ## LOW TEMP DATA DATES ##\n",
    "        #---------------------------------------------------------------\n",
    "        # check how many lines exist in the list\n",
    "        # if only one line, then just one date to grab\n",
    "        if len(low_temp_data.splitlines()) == 1:\n",
    "        \n",
    "            data_dict[station][month]['low_dates'].append([filtered_low_temp_data[1]])\n",
    "        \n",
    "        # if there are multiple rows of low temp data, then multiple dates to grab\n",
    "        elif len(low_temp_data.splitlines()) > 1:\n",
    "            dates = []\n",
    "            \n",
    "            # grab the first date in the line\n",
    "            dates.append(filtered_low_temp_data[1])\n",
    "        \n",
    "            # now iterate and find the rest of the dates\n",
    "            for line in low_temp_data.splitlines()[1:]:\n",
    "                if count_spaces(line):\n",
    "                    dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "        \n",
    "            data_dict[station][month]['low_dates'].append(dates)\n",
    "\n",
    "        ## HIGH TEMP DATA DATES ##\n",
    "        #---------------------------------------------------------------\n",
    "        # check how many lines exist in the list\n",
    "        # if only one line, then just one date to grab\n",
    "        if len(high_temp_data.splitlines()) == 1:\n",
    "        \n",
    "            data_dict[station][month]['high_dates'].append([filtered_high_temp_data[1]])\n",
    "        \n",
    "        # if there are multiple rows of high temp data, then multiple dates to grab\n",
    "        elif len(high_temp_data.splitlines()) > 1:\n",
    "            dates = []\n",
    "            \n",
    "            # grab the first date in the line\n",
    "            dates.append(filtered_high_temp_data[1])\n",
    "        \n",
    "            # now iterate and find the rest of the dates\n",
    "            for line in high_temp_data.splitlines()[1:]:\n",
    "                if count_spaces(line):\n",
    "                    dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "        \n",
    "            data_dict[station][month]['high_dates'].append(dates)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    y = timestamp.year\n",
    "    m = timestamp.month\n",
    "    d = timestamp.day\n",
    "    hh = timestamp.hour\n",
    "    mm = timestamp.minute\n",
    "    \n",
    "    api_url = f'https://mesonet.agron.iastate.edu/api/1/nwstext/{y}{m:02}{d:02}{hh:02}{mm:02}-KLZK-CXUS54-{pil}'\n",
    "    print(api_url)\n",
    "    \n",
    "    html = urlopen(api_url).read()\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    \n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "    \n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # parse out the highest and lowest temp data for the month from the text\n",
    "    high_temp_data = text.split('HIGHEST         ')[-1].split('LOWEST')[0]   \n",
    "    low_temp_data = text.split('LOWEST           ')[-1].split('AVG. MAXIMUM')[0]  \n",
    "\n",
    "    get_maxmin_data(high_temp_data, low_temp_data, station, m)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "y = 2023\n",
    "months = [x for x in range(6)][2:]\n",
    "days = [x for x in range(21)][1:]\n",
    "#d = 15\n",
    "\n",
    "#station = 'LIT'\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# establish our main working dictionary\n",
    "data_dict = {}\n",
    "\n",
    "for s in ['LIT', 'LZK', 'HRO', 'PBF']:\n",
    "    _data_dict = {\n",
    "        f'{s}' : {}\n",
    "    }\n",
    "    data_dict.update(_data_dict)\n",
    "\n",
    "# now add the months\n",
    "for key in data_dict:\n",
    "    for i in range(1,13):\n",
    "        _data_dict = {\n",
    "             f'{calendar.month_name[i][:3].upper()}' : {# generate the abbreviated month names\n",
    "            'highs': [],\n",
    "            'high_dates': [], # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "            'lows': [],\n",
    "            'low_dates': []  # these should still contain 12 items, but will be lists inside lists in case of multiple dates                                     }\n",
    "                }\n",
    "            }\n",
    "        data_dict[key].update(_data_dict)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# apply a broad range of days to search over for the CLM products\n",
    "for m in months:\n",
    "\n",
    "    # boolean variable to use break on for for loop\n",
    "    product_found = False\n",
    "    \n",
    "    for d in days:\n",
    "\n",
    "        #url = f'https://mesonet.agron.iastate.edu/wx/afos/list.phtml?by=pil&pil=CLM&day={d:02}&month={m:02}&year={y}'\n",
    "        \n",
    "        url = f'https://mesonet.agron.iastate.edu/wx/afos/list.phtml?source=LZK&by=pil&pil=CLM&year={y}&month={m:02}&day={d:02}'\n",
    "        \n",
    "        print(url)\n",
    "        \n",
    "        html = urlopen(url).read()\n",
    "        soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "        \n",
    "        # kill all script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()    # rip it out\n",
    "        \n",
    "        #print(text)\n",
    "        \n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "\n",
    "        if 'KLZK' in text.split('Skip to cccc:')[-1]:\n",
    "\n",
    "            # convert product_found variable to True\n",
    "            product_found = True\n",
    "            \n",
    "            text = text.split('Skip to cccc:')[-1].split('College of Ag\\n')[0]\n",
    "\n",
    "            # declare a new dictionary    \n",
    "            # station_time_dict = {\n",
    "            #     'station' : ['LIT', 'LZK', 'HRO', 'PBF'],\n",
    "            #     'product_time' : []\n",
    "            # }\n",
    "\n",
    "\n",
    "            # now lets iterate through the four PILs\n",
    "            for station in ['LIT', 'LZK', 'HRO', 'PBF']:\n",
    "                if f'CLM{station}' in text:\n",
    "\n",
    "                    product_time = text.split(f'CLM{station}')[-1].split('@')[-1].split('\\n')[0]\n",
    "\n",
    "                    # parse out the hour and minute from the product_time variable\n",
    "                    hh = datetime.strptime(product_time, '%H:%M').hour\n",
    "                    mm = datetime.strptime(product_time, '%H:%M').minute\n",
    "\n",
    "                    # set up a timestamp object\n",
    "                    timestamp = parse_timestamp(y, m, d, hh, mm)\n",
    "\n",
    "                    text_parser(timestamp, f'CLM{station}')\n",
    "\n",
    "                    #print(\n",
    "                    #station_time_dict['product_time'].append(product_time)\n",
    "                    #print(station, time)\n",
    "\n",
    "            #print(station_time_dict)\n",
    "\n",
    "        # exit the for loop for iterating through days and move onto the next month in the parent for loop\n",
    "        if product_found:\n",
    "            break\n",
    "\n",
    "        # if we haven't found what we're looking for, then continue onto the next day in the iteration\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed1e5b-3303-449a-88df-393df5b48b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac3e2f-16a4-47a9-bcc9-fc605f92d163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52c3e3-63c9-410a-98ab-b647eb43fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os, sys\n",
    "import itertools\n",
    "from datetime import datetime, timezone\n",
    "import calendar\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import textwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "de265291-c557-443c-a4b2-0277a575524c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "14\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNotes, this all *appears* to be working, will need to test it out over some years and sites...\\n\\n'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Working here, 08/02/2024\n",
    "\n",
    "We made a function that will fetch the API links of CLM products, and save us some headache of generating those by\n",
    "parsing the raw NWS text product web page text. Now with the API links, we can iterate through the links, and generate\n",
    "the data and text files for the CLA products, iterating for each station/pil.\n",
    "\n",
    "'''\n",
    "# ----------------------------------------------------------\n",
    "# Helping Functions\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def get_product_links(pil, y):\n",
    "\n",
    "    '''\n",
    "    A function that will query the IEM API for CLM products, and return the corresponding API links to those products\n",
    "\n",
    "    pil : str, 6 character pil for CLM products, e.g., CLMLIT\n",
    "    y : int, year in YYYY format\n",
    "    \n",
    "    returns:\n",
    "    api_links : list, a list of API link strings\n",
    "    \n",
    "    '''\n",
    "\n",
    "    print(f'Searching for {y} {pil} products...\\n')\n",
    "    \n",
    "    # declare year and months to query\n",
    "    # for a year in review, need to get Feb (Jan) to Dec (Nov), then Jan (Dec) of the new year, to complete one calendar year\n",
    "    \n",
    "    #y = datetime.now().year\n",
    "    months = [x for x in range(13)][2:] # start in feb for jan CLM product\n",
    "    days = [x for x in range(15)][1:]\n",
    "\n",
    "    \n",
    "    # empty list to store api_links for each monthly product\n",
    "    api_links = []\n",
    "    \n",
    "    for m in months:\n",
    "        print(f'---{calendar.month_name[m][:3]} {y}---')\n",
    "        for d in days:\n",
    "\n",
    "            # this is the api link that returns a json file with info, either including product issuance info, or little info, in json format\n",
    "            #url = 'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil=CLMLIT&date=2023-02-04'\n",
    "            url = f'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil={pil}&date={y}-{m:02}-{d:02}'\n",
    "            \n",
    "            # A GET request to the API\n",
    "            response = requests.get(url)\n",
    "\n",
    "            # turn the request into a json, and subsequently a dictionary\n",
    "            response = response.json()\n",
    "    \n",
    "            if not response['data']:\n",
    "                print(f'   -No {pil} product issued on {m:02}/{d:02}/{y}')\n",
    "                continue\n",
    "    \n",
    "            elif response['data']:\n",
    "                print(f'   -{pil} Product issued on {m:02}/{d:02}/{y}\\n')\n",
    "                api_links.append(response['data'][0]['text_link'])\n",
    "                break\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # small section to do dec, because the dec CLM product is issued in jan of the following year\n",
    "    m = 1\n",
    "    print(f'---{calendar.month_name[m][:3]} {y}---')\n",
    "    for d in days:\n",
    "\n",
    "        url = f'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil={pil}&date={y+1}-{m:02}-{d:02}'\n",
    "        \n",
    "        # A GET request to the API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # turn the request into a json, and subsequently a dictionary\n",
    "        response = response.json()\n",
    "\n",
    "        if not response['data']:\n",
    "            print(f'   -No {pil} product issued on {m:02}/{d:02}/{y}')\n",
    "            continue\n",
    "\n",
    "        elif response['data']:\n",
    "            print(f'   -{pil} Product issued on {m:02}/{d:02}/{y}\\n')\n",
    "            api_links.append(response['data'][0]['text_link'])\n",
    "            break\n",
    "\n",
    "    print(f'Finished searching for {y} {pil} products...\\n')\n",
    "    return api_links\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# def count_spaces(line):\n",
    "\n",
    "#     # this should be the date in the line\n",
    "#     split_date = list(filter(None, (line.split(' '))))[0]\n",
    "\n",
    "#     # this is the number of spaces for it to be a date occurred that month\n",
    "#     if line.split(split_date)[0].count(' ') < 30:\n",
    "#         return True\n",
    "\n",
    "#     else:\n",
    "#         return False\n",
    "        \n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def parse_timestamp(url):\n",
    "\n",
    "    '''\n",
    "    This function will take a url string, and create a datetime object from the timestamp in the url.\n",
    "\n",
    "    url : str, the API url with the timestamp in the url\n",
    "\n",
    "    returns:\n",
    "    timestamp : a datetime object with the url timestamp\n",
    "    station : str, the three letter station ID\n",
    "\n",
    "    '''\n",
    "    \n",
    "    timestamp = url.split('nwstext/')[-1].split('-KLZK')[0]\n",
    "    \n",
    "    y = int(timestamp[:4])\n",
    "    m = int(timestamp[4:6])\n",
    "    # if the month of the timestamp is january, then this is the dec product\n",
    "    if m == 1:\n",
    "        m = 12\n",
    "    # otherwise, apply the standard correction of one month subtracted\n",
    "    else:\n",
    "        m = m-1\n",
    "    d = int(timestamp[6:8])\n",
    "    hh = int(timestamp[8:10])\n",
    "    mm = int(timestamp[10:])\n",
    "\n",
    "    station = url.split('CLM')[-1]\n",
    "    \n",
    "    return datetime(y, m , d, hh, mm), station\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "def parse_clm_text(url):\n",
    "\n",
    "    '''\n",
    "    This function will parse the API url text for climate data, and return the unfiltered text info to keys in a dictionary.\n",
    "\n",
    "    url : str, the API url\n",
    "\n",
    "    returns:\n",
    "    text_dict : dictionary, the dictionary with all unfiltered climate text info\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    \n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "    \n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # parse out the highest and lowest temp data for the month from the text\n",
    "    high_temp_data = text.split('HIGHEST         ')[-1].split('LOWEST')[0]   \n",
    "    low_temp_data = text.split('LOWEST           ')[-1].split('AVG. MAXIMUM')[0]  \n",
    "\n",
    "    # parse out the avg high and low temp data, and the avg monthly temp data\n",
    "    avg_high_temp_data = text.split('AVG. MAXIMUM  ')[-1].split('\\nAVG. MINIMUM  ')[0]   \n",
    "    avg_low_temp_data = text.split('AVG. MINIMUM  ')[-1].split('\\nMEAN')[0]  \n",
    "    avg_monthly_data = text.split('MEAN  ')[-1].split('\\nDAYS MAX >= 90')[0]\n",
    "\n",
    "    # parse out the precip and snow data\n",
    "    monthly_precip_data = text.split('SNOWFALL (INCHES)')[0].split('PRECIPITATION (INCHES)')[-1].split('\\nTOTALS')[-1]\n",
    "    monthly_snow_data = text.split('SNOWFALL (INCHES)')[-1].split('\\nTOTALS')[-1].split('\\nDEGREE DAYS')[0]\n",
    "\n",
    "    values = [high_temp_data, low_temp_data, \n",
    "                avg_high_temp_data, avg_low_temp_data, avg_monthly_data, \n",
    "                monthly_precip_data, monthly_snow_data]\n",
    "\n",
    "    keys = ['high_temp_data_text', 'low_temp_data_text',\n",
    "            'avg_high_temp_data_text', 'avg_low_temp_data_text', 'avg_monthly_data_text',\n",
    "            'monthly_precip_data_text', 'monthly_snow_data_text']\n",
    "    \n",
    "    text_dict = dict(zip(keys, values)) \n",
    "\n",
    "    \n",
    "    return text_dict\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def get_temp_data(high_temp_data, low_temp_data, avg_high_temp_data, avg_low_temp_data, avg_monthly_data, month):\n",
    "\n",
    "    '''\n",
    "    Worker function to extract high and low data/dates from the CLM products.\n",
    "\n",
    "    high_temp_data : str, a parsed string that contains the monthly high temp data from the CLM\n",
    "    low_temp_data : str, a parsed string that contains the monthly low temp data from the CLM\n",
    "    avg_high_temp_data : str, a parsed string that contains the avg monthly high temp data from the CLM\n",
    "    avg_low_temp_data : str, a parsed string that contains the avg monthly low temp data from the CLM\n",
    "    avg_monthly_data : str, a parsed string that contains the avg monthly mean temp data from the CLM\n",
    "    (no longer needed) station : str, the three character station ID for each climate site\n",
    "    month : int, the numerical month number, can be obtained from the timestamp variable\n",
    "\n",
    "    returns:\n",
    "    None\n",
    "    \n",
    "    '''\n",
    "    # Helper functions\n",
    "    # --------------------------------------------------------\n",
    "    def _count_spaces(line):\n",
    "\n",
    "        # this should be the date in the line\n",
    "        split_date = list(filter(None, (line.split(' '))))[0]\n",
    "    \n",
    "        # this is the number of spaces for it to be a date occurred that month\n",
    "        if line.split(split_date)[0].count(' ') < 30:\n",
    "            return True\n",
    "    \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    \n",
    "    month = calendar.month_name[month][:3].upper()\n",
    "    \n",
    "    # first filter the line of temp data\n",
    "    filtered_low_temp_data = list(filter(None, low_temp_data.split(' '))) # low temp data\n",
    "    filtered_high_temp_data = list(filter(None, high_temp_data.split(' '))) # high temp data\n",
    "    \n",
    "    # lets add the high and low values to the dictionary\n",
    "    data_dict[month]['monthly_max_min'].append(int(filtered_high_temp_data[0]))\n",
    "    data_dict[month]['monthly_max_min'].append(int(filtered_low_temp_data[0]))\n",
    "\n",
    "    # now add the monthly avg high, low, and avg temps, and dfn\n",
    "    data_dict[month]['monthly_avg_temps_dfn'].append(float(list(filter(None, (avg_high_temp_data.split(' '))))[0])) # monthly avg high\n",
    "    data_dict[month]['monthly_avg_temps_dfn'].append(float(list(filter(None, (avg_low_temp_data.split(' '))))[0])) # monthly avg low\n",
    "    data_dict[month]['monthly_avg_temps_dfn'].append(float(list(filter(None, (avg_monthly_data.split(' '))))[0])) # monthly avg mean temp\n",
    "    data_dict[month]['monthly_avg_temps_dfn'].append(float(list(filter(None, (avg_monthly_data.split(' '))))[2])) # monthly avg mean temp dfn\n",
    "    \n",
    "    ## LOW TEMP DATA DATES ##\n",
    "    #---------------------------------------------------------------\n",
    "    # check how many lines exist in the list\n",
    "    # if only one line, then just one date to grab\n",
    "    if len(low_temp_data.splitlines()) == 1:\n",
    "        data_dict[month].update({'low_dates' : str(filtered_low_temp_data[1])})\n",
    "\n",
    "    # if there are multiple lines of low temp data, then check if these are the dates (occurrence dates, not records) that we want\n",
    "    elif len(low_temp_data.splitlines()) > 1 and not count_spaces(low_temp_data.splitlines()[1]):\n",
    "        data_dict[month].update({'low_dates' : str(filtered_low_temp_data[1])})\n",
    "        \n",
    "    # if there are multiple rows of low temp data, then multiple dates to grab that are valid\n",
    "    else:\n",
    "        # grab the first date in the line\n",
    "        data_dict[month].update({'low_dates' : [filtered_low_temp_data[1]]})\n",
    "        \n",
    "        # now iterate and find the rest of the dates\n",
    "        for line in low_temp_data.splitlines()[1:]:\n",
    "            if _count_spaces(line):\n",
    "                data_dict[month]['low_dates'].append(list(filter(None, (line.split(' '))))[0])\n",
    "\n",
    "\n",
    "    ## HIGH TEMP DATA DATES ##\n",
    "    #---------------------------------------------------------------\n",
    "    # check how many lines exist in the list\n",
    "    # if only one line, then just one date to grab\n",
    "    if len(high_temp_data.splitlines()) == 1:\n",
    "        data_dict[month].update({'high_dates' : str(filtered_high_temp_data[1])})\n",
    "\n",
    "    # if there are multiple lines of high temp data, then check if these are the dates (occurrence dates, not records) that we want\n",
    "    elif len(high_temp_data.splitlines()) > 1 and not count_spaces(high_temp_data.splitlines()[1]):\n",
    "        data_dict[month].update({'high_dates' : str(filtered_high_temp_data[1])})\n",
    "\n",
    "    # if there are multiple rows of high temp data, then multiple dates to grab\n",
    "    else:\n",
    "        \n",
    "        # grab the first date in the line\n",
    "        data_dict[month].update({'high_dates' : [filtered_high_temp_data[1]]})\n",
    "    \n",
    "        # now iterate and find the rest of the dates\n",
    "        for line in high_temp_data.splitlines()[1:]:\n",
    "            if _count_spaces(line):\n",
    "                data_dict[month]['high_dates'].append(list(filter(None, (line.split(' '))))[0])\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def get_precip_data(monthly_precip_data, month):\n",
    "\n",
    "    '''\n",
    "    This function will parse the precip text info from the API url, and will append precip data\n",
    "    to the main working dictionary.\n",
    "\n",
    "    monthly_precip_data : str, the parsed monthly precip data as a string\n",
    "    month : int, the month as an integer\n",
    "\n",
    "    returns: \n",
    "    None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Helper Sub-function of the main function        \n",
    "    # --------------------------------------------------------   \n",
    "    \n",
    "    def _check_record(param):\n",
    "        if 'R' in str(param):\n",
    "            return param.split('R')[0]\n",
    "        else:\n",
    "            return param\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    \n",
    "    # convert the integer month to the three letter month name\n",
    "    month = calendar.month_name[month][:3].upper()\n",
    "\n",
    "\n",
    "    # ---- Monthly Rain Data -----\n",
    "    monthly_total_rain = _check_record(list(filter(None, (monthly_precip_data.split(' '))))[0]) # monthly total rain\n",
    "    monthly_rain_dfn = _check_record(list(filter(None, (monthly_precip_data.split(' '))))[2])\n",
    "    \n",
    "    # add the monthly precip total and dfn\n",
    "    data_dict[month]['monthly_rain_and_dfn'].append(float(monthly_total_rain)) # monthly total\n",
    "    data_dict[month]['monthly_rain_and_dfn'].append(float(monthly_rain_dfn)) # monthly dfn\n",
    "\n",
    "    # now lets get the calendar max, 24 hr max values and dates for rain\n",
    "    for idx, line in enumerate(monthly_precip_data.split('\\nGREATEST\\n')[-1].splitlines()):\n",
    "        #print(list(filter(None, (line.split(' ')))))\n",
    "        if idx == 0:\n",
    "            max_clndr_rain = float(list(filter(None, (line.split(' '))))[3])\n",
    "            max_clndr_rain_dates = \" \".join(list(filter(None, (line.split(' '))))[4:])\n",
    "    \n",
    "        elif idx == 1:\n",
    "            max_stormtotal_rain = float(list(filter(None, (line.split(' '))))[-1])\n",
    "    \n",
    "    # check for a different max storm total rainfall date\n",
    "    lst = monthly_precip_data.split('\\nGREATEST\\n')[-1][:-2].splitlines()\n",
    "    empty_date = '(MM/DD(HH))' # string we are searching for that designates no storm total date i.e. it equals the 24 hr total\n",
    "    \n",
    "    # if we find the empty_date search string, then add the 24 hr total dates to storm total dates\n",
    "    if any(empty_date in x for x in lst):\n",
    "        #max_stormtotal_rain_dates = \" \".join(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n')[-1][:-2].splitlines()[0].split(' '))))[4:])\n",
    "        max_stormtotal_rain_dates = max_clndr_rain_dates\n",
    "        \n",
    "    # if we do not find the empty_date search string, then handle adding a potentially different storm total date\n",
    "    else:\n",
    "        max_stormtotal_rain_dates = \" \".join(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n')[-1][:-2].splitlines()[1].split(' '))))[3:])\n",
    "        \n",
    "    # 24 hour (calendar day max) rainfall data\n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_clndr_rain) # 24 hr max (calendar day max)\n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_clndr_rain_dates) # 24 hr max dates\n",
    "    \n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_stormtotal_rain) # max storm total \n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_stormtotal_rain_dates) # max storm total dates (set equal to 24 hr max for now)\n",
    "\n",
    "\n",
    "\n",
    "def get_snow_data(monthly_snow_data, month):\n",
    "\n",
    "    '''\n",
    "    This function will parse the precip text info from the API url, and will append snow data\n",
    "    to the main working dictionary.\n",
    "\n",
    "    monthly_snow_data : str, the parsed monthly snow data as a string\n",
    "    month : int, the month as an integer\n",
    "\n",
    "    returns: \n",
    "    None\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Helper Sub-functions of the main function\n",
    "    # --------------------------------------------------------\n",
    "    def _check_record(param):\n",
    "        if 'R' in str(param):\n",
    "            return param.split('R')[0]\n",
    "        else:\n",
    "            return param\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def _check_missing_snow(param, month):\n",
    "        try:\n",
    "            data_dict[month]['monthly_snow_sdepth_dfn'].append(float(param))\n",
    "        \n",
    "        except ValueError:\n",
    "            if 'T' in str(param):\n",
    "                data_dict[month]['monthly_snow_sdepth_dfn'].append(param) \n",
    "            else:\n",
    "                data_dict[month]['monthly_snow_sdepth_dfn'].append(0.0)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "\n",
    "    # first, if month is not in a primary cool season month, then auto fill values and end the function call\n",
    "    if month not in [1, 2, 3, 4, 10, 11, 12]:\n",
    "\n",
    "        # convert the integer month to the three letter month name\n",
    "        month = calendar.month_name[month][:3].upper()\n",
    "        \n",
    "        # this will add [0.0, 0.0, 0.0, np.nan]\n",
    "        blank_values = [0.0, 0.0, 0.0, np.nan]\n",
    "        data_dict[month].update({'monthly_snow_sdepth_dfn' : blank_values})\n",
    "\n",
    "        # for i in range(3):\n",
    "        #     data_dict[month]['monthly_snow_sdepth_dfn'].append(0.0)\n",
    "        # data_dict[month]['monthly_snow_sdepth_dfn'].append(np.nan)\n",
    "\n",
    "        # this will add [0.0, np.nan]\n",
    "        blank_values = [0.0, np.nan]\n",
    "        data_dict[month].update({'max_clndr_24hr_snow' : blank_values})\n",
    "        # data_dict[month]['max_clndr_24hr_snow'].append(0.0)\n",
    "        # data_dict[month]['max_clndr_24hr_snow'].append(np.nan) \n",
    "        return\n",
    "        \n",
    "\n",
    "    # if we do have cool season month, then proceed \n",
    "\n",
    "    # convert the integer month to the three letter month name\n",
    "    month = calendar.month_name[month][:3].upper()\n",
    "    \n",
    "\n",
    "    # ---- Monthly Snow Data ----\n",
    "    # add the monthly snow total and dfn\n",
    "    monthly_total_snow = _check_record(list(filter(None, (monthly_snow_data.split(' '))))[0]) # monthly total snow\n",
    "    monthly_grtst_sdepth = _check_record(list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n SNOW DEPTH')[-1].splitlines()[0].split(' '))))[0]) # monthly greatest snow depth\n",
    "    monthly_snow_dfn = _check_record(list(filter(None, (monthly_snow_data.split(' '))))[2]) # monthly total snow dfn\n",
    "    monthly_grtst_24hr_snow = _check_record(list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n')[-1].split(' 24 HR TOTAL')[-1].splitlines()[0].split(' '))))[0])\n",
    "\n",
    "    # Add the data to the main dictionary\n",
    "    # for the non winter months, monthly snow may just be set to 'MM' in the CLM product\n",
    "    _check_missing_snow(monthly_total_snow, month) # this will add the monthly total snow\n",
    "    _check_missing_snow(monthly_snow_dfn, month) # this will add the monthly total snow dfn  \n",
    "    _check_missing_snow(monthly_grtst_sdepth, month) # this will add the greatest monthly snow depth\n",
    "\n",
    "\n",
    "    \n",
    "    # ---- Greatest Snow Depth Dates ----\n",
    "    # Now lets check for dates on greatest snow depth and 24 max total\n",
    "    lst = monthly_snow_data.split('\\nGREATEST\\n')[-1].splitlines()\n",
    "    \n",
    "    # if monthly max snow depth is missing, set dates to nan\n",
    "    if monthly_grtst_sdepth in ['0', 'MM']:\n",
    "    #if monthly_grtst_sdepth == 'MM':\n",
    "        monthly_grtst_sdepth_dates = np.nan\n",
    "    \n",
    "    # for greatest snow depth date (multiple dates)\n",
    "    if any('/' in x for x in lst[0]) and len(lst) > 2:\n",
    "    \n",
    "        monthly_grtst_sdepth_dates = []\n",
    "    \n",
    "        # get the first date and make sure it is valid\n",
    "        split_date = list(filter(None, (lst[0].split(' '))))[-1]\n",
    "        if lst[0].split(split_date)[0].split(monthly_grtst_sdepth)[-1].count(' ') <= 3:\n",
    "            monthly_grtst_sdepth_dates.append(split_date)\n",
    "    \n",
    "        # now iterate over the remainder of possible dates\n",
    "        for idx, item in enumerate(lst[1:-1]): # skip the first, and the last line because the last line is the 24 hr max data\n",
    "            split_date = list(filter(None, (item.split(' '))))[0]\n",
    "            if lst[idx].split(split_date).count(' ') <= 25:\n",
    "                monthly_grtst_sdepth_dates.append(split_date)\n",
    "    \n",
    "    # for greatest snow depth date (only one date)\n",
    "    elif any('/' in x for x in lst[0]) and len(lst) == 2:\n",
    "        \n",
    "        # get the first date and make sure it is valid\n",
    "        split_date = list(filter(None, (lst[0].split(' '))))[-1]\n",
    "        if lst[0].split(split_date)[0].split(monthly_grtst_sdepth)[-1].count(' ') <= 3:\n",
    "            monthly_grtst_sdepth_dates = split_date   \n",
    "    else:\n",
    "        monthly_grtst_sdepth_dates = np.nan\n",
    "\n",
    "    \n",
    "    # ---- Max 24 hr Snow Dates ----\n",
    "    # lets follow similar logic here...\n",
    "    \n",
    "    # if monthly max 24 hr snow is missing, then set dates to nan\n",
    "    if monthly_grtst_24hr_snow in ['0.0', 'MM']:\n",
    "    #if monthly_grtst_24hr_snow == 'MM':\n",
    "        monthly_grtst_24hr_snow_dates = np.nan\n",
    "    \n",
    "    # for greatest snow depth date\n",
    "    elif any('/' in x for x in lst[-1]):\n",
    "    \n",
    "        # lets get the first occurrence of a date and use that to split\n",
    "        first_date = list(filter(None, (lst[-1].split(monthly_grtst_24hr_snow)[-1].split('TO')[0].split(' '))))\n",
    "        first_date = list(filter(lambda k: 'R' not in k, first_date)) # in case there is a record value for 24 hr snow, there will still be an 'R'\n",
    "        \n",
    "        # now lets split based on the first date and count the spaces\n",
    "        if lst[-1].split(first_date[0]).count(' ') <= 4:\n",
    "            monthly_grtst_24hr_snow_dates = \" \".join(list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n')[-1].splitlines()[1].split(' '))))[4:7])\n",
    "        \n",
    "        else:\n",
    "            monthly_grtst_24hr_snow_dates = np.nan\n",
    "    \n",
    "    else:\n",
    "        monthly_grtst_24hr_snow_dates = np.nan\n",
    "\n",
    "\n",
    "    # now add the data to the main dictionary\n",
    "    data_dict[month]['monthly_snow_sdepth_dfn'].append(monthly_grtst_sdepth_dates) # add the greatest snow depth date(s) to the dictionary\n",
    "    \n",
    "    try:\n",
    "        data_dict[month]['max_clndr_24hr_snow'].append(float(monthly_grtst_24hr_snow)) # add the greatest 24 hr snow total to the dictionary\n",
    "    except ValueError:\n",
    "        if monthly_grtst_24hr_snow in ['0.0', 'MM']:\n",
    "            data_dict[month]['max_clndr_24hr_snow'].append(0.0) # add the greatest 24 hr snow total to the dictionary \n",
    "        elif monthly_grtst_24hr_snow in ['T']:\n",
    "            data_dict[month]['max_clndr_24hr_snow'].append('T') # add trace for the greatest 24 hr snow total to the dictionary\n",
    "        \n",
    "    data_dict[month]['max_clndr_24hr_snow'].append(monthly_grtst_24hr_snow_dates) # add the greatest 24 hr snow total dates to the dictionary    \n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------  \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main script begins here...\n",
    "\n",
    "# -----------------------------------\n",
    "# establish our main working dictionary\n",
    "# data_dict = {}\n",
    "\n",
    "# for s in ['LIT', 'LZK', 'HRO', 'PBF']:\n",
    "#     _data_dict = {\n",
    "#         f'{s}' : {}\n",
    "#     }\n",
    "#     data_dict.update(_data_dict)\n",
    "\n",
    "# # now add the months\n",
    "# for key in data_dict:\n",
    "#     for i in range(1,13):\n",
    "#         _data_dict = {\n",
    "#             # generate the abbreviated month names\n",
    "#              f'{calendar.month_name[i][:3].upper()}' : {\n",
    "#             'monthly_max_min': [],\n",
    "#             'high_dates': None,\n",
    "#             'low_dates': None,\n",
    "#             'monthly_avg_temps_dfn' : [], # avg high, low, mean, mean dfn\n",
    "#             'monthly_rain_and_dfn' : [], # monthly total rain and dfn\n",
    "#             'max_clndr_24hr_rain' : [],\n",
    "#             'monthly_snow_sdepth_dfn' : [], # monthly total rain and dfn\n",
    "#             'max_clndr_24hr_snow' : []\n",
    "#                 }\n",
    "#             }\n",
    "#         data_dict[key].update(_data_dict)\n",
    "\n",
    "# -----------------------------------\n",
    "# using this for dictionary structure instead, \n",
    "# only going to focus on one station at a time for each call of the main() function\n",
    "\n",
    "# establish our main working dictionary\n",
    "data_dict = {}\n",
    "\n",
    "for i in range(1,13):\n",
    "    _data_dict = {f'{calendar.month_name[i][:3].upper()}' : {}}\n",
    "    data_dict.update(_data_dict)\n",
    "\n",
    "\n",
    "# now add the months\n",
    "for key in data_dict:\n",
    "    _data_dict = {\n",
    "        # generate the abbreviated month names\n",
    "         #f'{calendar.month_name[i][:3].upper()}' : {\n",
    "        'monthly_max_min': [],\n",
    "        'high_dates': None,\n",
    "        'low_dates': None,\n",
    "        'monthly_avg_temps_dfn' : [], # avg high, low, mean, mean dfn\n",
    "        'monthly_rain_and_dfn' : [], # monthly total rain and dfn\n",
    "        'max_clndr_24hr_rain' : [], # [max calendar day rainfall (float), dates, max 24 hr rainfall (float), dates]\n",
    "        'monthly_snow_sdepth_dfn' : [], # monthly total snow, total snow dfn, greatest snow depth, and date(s) of greatest snow depth\n",
    "        'max_clndr_24hr_snow' : [] # max 24 hr total snow and date(s) of 24 hr total snow\n",
    "        }\n",
    "    \n",
    "    data_dict[key].update(_data_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# keep this here to only have to run for api links when necessary, this is time consuming\n",
    "# first lets get the API links for a station\n",
    "#api_links = get_product_links(', year) # these variables will be replaced with place holders in the main function\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "def construct_data_dict(pil, year):\n",
    "    \n",
    "    # first lets get the API links for a station\n",
    "    #api_links = get_product_links(pil, year) # these variables will be replaced with place holders in the main function\n",
    "    \n",
    "    \n",
    "    for url in api_links:\n",
    "    \n",
    "        timestamp, station = parse_timestamp(url) # get the datetime and station from the url string\n",
    "        #high_temp_data, low_temp_data = parse_clm_text(url) # this will get the high temp and low temp data from the text within the url\n",
    "        text_dict = parse_clm_text(url) # this will get the high temp and low temp data from the text within the url\n",
    "    \n",
    "        # parse the high/low temp and add it to the main data dictionary\n",
    "        get_temp_data(text_dict['high_temp_data_text'], text_dict['low_temp_data_text'], \n",
    "                        text_dict['avg_high_temp_data_text'], text_dict['avg_low_temp_data_text'], text_dict['avg_monthly_data_text'],\n",
    "                        timestamp.month)\n",
    "\n",
    "        # parse the precip data and add it to the main data dictionary\n",
    "        get_precip_data(text_dict['monthly_precip_data_text'], timestamp.month)\n",
    "    \n",
    "        # parse the snow data and add it to the main data dictionary\n",
    "        get_snow_data(text_dict['monthly_snow_data_text'], timestamp.month)\n",
    "\n",
    "def main(pil, year):\n",
    "    construct_data_dict(pil, year)\n",
    "\n",
    "main('CLMLZK', 2021)\n",
    "\n",
    "#data_dict['LZK']\n",
    "\n",
    "\n",
    "'''\n",
    "Notes, this all *appears* to be working, will need to test it out over some years and sites...\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "912e06b4-eb1d-4b1b-a4b2-b1980df222e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JAN': {'monthly_max_min': [73, 24],\n",
       "  'high_dates': '01/25',\n",
       "  'low_dates': '01/12',\n",
       "  'monthly_avg_temps_dfn': [49.8, 34.3, 42.1, 1.0],\n",
       "  'monthly_rain_and_dfn': [2.74, -0.68],\n",
       "  'max_clndr_24hr_rain': [0.78, '01/24 TO 01/24', 0.78, '01/24 TO 01/24'],\n",
       "  'monthly_snow_sdepth_dfn': ['T', -1.7, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['T', '01/15 TO 01/15']},\n",
       " 'FEB': {'monthly_max_min': [73, -1],\n",
       "  'high_dates': ['02/23', '02/28'],\n",
       "  'low_dates': '02/16',\n",
       "  'monthly_avg_temps_dfn': [42.9, 27.8, 35.4, -9.9],\n",
       "  'monthly_rain_and_dfn': [5.23, 1.57],\n",
       "  'max_clndr_24hr_rain': [1.81, '02/28 TO 02/28', 1.81, '02/28 TO 02/28'],\n",
       "  'monthly_snow_sdepth_dfn': [18.7, 16.9, 14.0, '02/18'],\n",
       "  'max_clndr_24hr_snow': ['10.9', '02/14 TO 02/15']},\n",
       " 'MAR': {'monthly_max_min': [80, 33],\n",
       "  'high_dates': '03/27',\n",
       "  'low_dates': '03/03',\n",
       "  'monthly_avg_temps_dfn': [66.2, 46.9, 56.5, 2.6],\n",
       "  'monthly_rain_and_dfn': [5.98, 1.21],\n",
       "  'max_clndr_24hr_rain': [2.36, '03/17 TO 03/17', 2.36, '03/17 TO 03/17'],\n",
       "  'monthly_snow_sdepth_dfn': ['T', -0.4, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['T', '03/31 TO 03/31']},\n",
       " 'APR': {'monthly_max_min': [84, 32],\n",
       "  'high_dates': '04/12',\n",
       "  'low_dates': '04/21',\n",
       "  'monthly_avg_temps_dfn': [69.7, 49.1, 59.4, -3.4],\n",
       "  'monthly_rain_and_dfn': [4.16, -0.63],\n",
       "  'max_clndr_24hr_rain': [1.15, '04/29 TO 04/29', 1.15, '04/29 TO 04/29'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['0.0', nan]},\n",
       " 'MAY': {'monthly_max_min': [87, 49],\n",
       "  'high_dates': '05/27',\n",
       "  'low_dates': '05/05',\n",
       "  'monthly_avg_temps_dfn': [76.7, 58.2, 67.5, -2.5],\n",
       "  'monthly_rain_and_dfn': [5.72, 0.33],\n",
       "  'max_clndr_24hr_rain': [1.49, '05/18 TO 05/18', 1.49, '05/18 TO 05/18'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': [0.0, nan]},\n",
       " 'JUN': {'monthly_max_min': [93, 58],\n",
       "  'high_dates': '06/12',\n",
       "  'low_dates': '06/23',\n",
       "  'monthly_avg_temps_dfn': [86.5, 69.4, 78.0, -0.0],\n",
       "  'monthly_rain_and_dfn': [3.7, 0.3],\n",
       "  'max_clndr_24hr_rain': [2.44, '06/07 TO 06/08', 1.52, '06/07 TO 06/08'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': [0.0, nan]},\n",
       " 'JUL': {'monthly_max_min': [96, 62],\n",
       "  'high_dates': ['07/31', '07/28'],\n",
       "  'low_dates': '07/04',\n",
       "  'monthly_avg_temps_dfn': [89.2, 71.2, 80.2, -1.2],\n",
       "  'monthly_rain_and_dfn': [3.48, -0.44],\n",
       "  'max_clndr_24hr_rain': [1.31, '07/25 TO 07/25', 1.31, '07/25 TO 07/25'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': [0.0, nan]},\n",
       " 'AUG': {'monthly_max_min': [98, 65],\n",
       "  'high_dates': '08/25',\n",
       "  'low_dates': ['08/04', '08/05'],\n",
       "  'monthly_avg_temps_dfn': [91.1, 71.9, 81.5, 0.7],\n",
       "  'monthly_rain_and_dfn': [1.75, -1.82],\n",
       "  'max_clndr_24hr_rain': [1.15, '08/06 TO 08/06', 1.15, '08/06 TO 08/06'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': [0.0, nan]},\n",
       " 'SEP': {'monthly_max_min': [96, 54],\n",
       "  'high_dates': ['09/01', '09/04'],\n",
       "  'low_dates': '09/23',\n",
       "  'monthly_avg_temps_dfn': [86.2, 65.7, 75.9, 2.0],\n",
       "  'monthly_rain_and_dfn': [1.84, -1.21],\n",
       "  'max_clndr_24hr_rain': [0.73, '09/05 TO 09/05', 0.73, '09/05 TO 09/05'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': [0.0, nan]},\n",
       " 'OCT': {'monthly_max_min': [86, 47],\n",
       "  'high_dates': '10/08',\n",
       "  'low_dates': ['10/26', '10/29'],\n",
       "  'monthly_avg_temps_dfn': [75.8, 57.6, 66.7, 3.8],\n",
       "  'monthly_rain_and_dfn': [9.79, 5.17],\n",
       "  'max_clndr_24hr_rain': [5.78, '10/02 TO 10/03', 5.27, '10/02 TO 10/03'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, 0.0, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['0.0', nan]},\n",
       " 'NOV': {'monthly_max_min': [73, 29],\n",
       "  'high_dates': '11/17',\n",
       "  'low_dates': '11/26',\n",
       "  'monthly_avg_temps_dfn': [59.8, 40.6, 50.2, -1.1],\n",
       "  'monthly_rain_and_dfn': [2.24, -2.45],\n",
       "  'max_clndr_24hr_rain': [1.07, '11/11 TO 11/11', 1.07, '11/11 TO 11/11'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, -0.1, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['0.0', nan]},\n",
       " 'DEC': {'monthly_max_min': [76, 29],\n",
       "  'high_dates': ['12/25', '12/10', '12/02'],\n",
       "  'low_dates': '12/20',\n",
       "  'monthly_avg_temps_dfn': [62.9, 45.7, 54.3, 11.1],\n",
       "  'monthly_rain_and_dfn': [5.01, -0.09],\n",
       "  'max_clndr_24hr_rain': [1.52, '12/29 TO 12/29', 1.52, '12/29 TO 12/29'],\n",
       "  'monthly_snow_sdepth_dfn': [0.0, -0.6, 0.0, nan],\n",
       "  'max_clndr_24hr_snow': ['0.0', nan]}}"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ead0a75-f677-4c5d-8f16-8f176867e8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 2021 CLMLZK products...\n",
      "\n",
      "---Feb 2021---\n",
      "   -No CLMLZK product issued on 02/01/2021\n",
      "   -CLMLZK Product issued on 02/02/2021\n",
      "\n",
      "---Mar 2021---\n",
      "   -No CLMLZK product issued on 03/01/2021\n",
      "   -No CLMLZK product issued on 03/02/2021\n",
      "   -No CLMLZK product issued on 03/03/2021\n",
      "   -No CLMLZK product issued on 03/04/2021\n",
      "   -CLMLZK Product issued on 03/05/2021\n",
      "\n",
      "---Apr 2021---\n",
      "   -No CLMLZK product issued on 04/01/2021\n",
      "   -CLMLZK Product issued on 04/02/2021\n",
      "\n",
      "---May 2021---\n",
      "   -CLMLZK Product issued on 05/01/2021\n",
      "\n",
      "---Jun 2021---\n",
      "   -CLMLZK Product issued on 06/01/2021\n",
      "\n",
      "---Jul 2021---\n",
      "   -No CLMLZK product issued on 07/01/2021\n",
      "   -CLMLZK Product issued on 07/02/2021\n",
      "\n",
      "---Aug 2021---\n",
      "   -CLMLZK Product issued on 08/01/2021\n",
      "\n",
      "---Sep 2021---\n",
      "   -CLMLZK Product issued on 09/01/2021\n",
      "\n",
      "---Oct 2021---\n",
      "   -No CLMLZK product issued on 10/01/2021\n",
      "   -CLMLZK Product issued on 10/02/2021\n",
      "\n",
      "---Nov 2021---\n",
      "   -No CLMLZK product issued on 11/01/2021\n",
      "   -CLMLZK Product issued on 11/02/2021\n",
      "\n",
      "---Dec 2021---\n",
      "   -No CLMLZK product issued on 12/01/2021\n",
      "   -CLMLZK Product issued on 12/02/2021\n",
      "\n",
      "---Jan 2021---\n",
      "   -No CLMLZK product issued on 01/01/2021\n",
      "   -No CLMLZK product issued on 01/02/2021\n",
      "   -No CLMLZK product issued on 01/03/2021\n",
      "   -CLMLZK Product issued on 01/04/2021\n",
      "\n",
      "Finished searching for 2021 CLMLZK products...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_links = get_product_links('CLMLZK', 2021) # these variables will be replaced with place holders in the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1473b6-6322-4dab-81ea-b2385d527c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "87243487-48b8-46bb-9c34-61d66bf2446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['          18.7R               1.8    16.9      0.3               ',\n",
       " ' LIQUID EQUIV   1.90               0.20    1.70     0.03               ',\n",
       " 'SINCE 7/1       18.8                4.0    14.8       MM               ',\n",
       " ' LIQUID 7/1     1.88               0.00    1.88       MM               ',\n",
       " 'SNOWDEPTH AVG.     2                                                   ',\n",
       " 'DAYS >= TRACE      6                1.2     4.8        3               ',\n",
       " 'DAYS >= 1.0        3                                   0               ',\n",
       " 'GREATEST',\n",
       " ' SNOW DEPTH       14R  02/18                                           ',\n",
       " ' 24 HR TOTAL    10.9R  02/14 TO 02/15                0.3  02/20 TO 02/20']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url = 'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLZK'\n",
    "url = 'https://mesonet.agron.iastate.edu/api/1/nwstext/202103050058-KLZK-CXUS54-CLMLZK'\n",
    "#url = 'https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMHRO' # multiple dates of greatest snow depth\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "avg_high_temp_data = text.split('AVG. MAXIMUM  ')[-1].split('\\nAVG. MINIMUM  ')[0]   \n",
    "avg_low_temp_data = text.split('AVG. MINIMUM  ')[-1].split('\\nMEAN')[0]  \n",
    "avg_monthly_data = text.split('MEAN  ')[-1].split('\\nDAYS MAX >= 90')[0]\n",
    "\n",
    "monthly_precip_data = text.split('SNOWFALL (INCHES)')[0].split('PRECIPITATION (INCHES)')[-1].split('\\nTOTALS')[-1]\n",
    "monthly_snow_data = text.split('SNOWFALL (INCHES)')[-1].split('\\nTOTALS')[-1].split('\\nDEGREE DAYS')[0]\n",
    "\n",
    "monthly_snow_data.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "3898c3aa-ead1-4f60-afff-6271e9dd8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Alrighty, now we have a script that will make us a dictionary... \n",
    "Lets try to write the data to tables in a text file...\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "def _make_temp_table(f, year, stn_name):\n",
    "\n",
    "    '''\n",
    "    This function will write in the annual temperature summary table to the supplemental CLA product text file.\n",
    "\n",
    "    f : file, the text file that is currently open that is being written to\n",
    "    year : int, the climate year\n",
    "    stn_name : str, the three letter climate station ID\n",
    "\n",
    "    returns:\n",
    "    None\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # put together the data for iterating quickly\n",
    "    months = [calendar.month_name[i][:3].upper() for i in range(1,13)]\n",
    "    \n",
    "    avg_high_temps = [data_dict[m]['monthly_avg_temps_dfn'][0] for m in months]\n",
    "    avg_low_temps = [data_dict[m]['monthly_avg_temps_dfn'][1] for m in months]\n",
    "    avg_temps = [data_dict[m]['monthly_avg_temps_dfn'][2] for m in months]\n",
    "    avg_temps_dfn = [data_dict[m]['monthly_avg_temps_dfn'][3] for m in months]\n",
    "    \n",
    "    high_temps = [data_dict[m]['monthly_max_min'][0] for m in months]\n",
    "    high_temp_dates = [data_dict[m]['high_dates'] for m in months]\n",
    "    \n",
    "    low_temps = [data_dict[m]['monthly_max_min'][1] for m in months]\n",
    "    low_temp_dates = [data_dict[m]['low_dates'] for m in months]\n",
    "\n",
    "    # now lets write the table into the text file\n",
    "    f.write(f'\\n{year} TEMPERATURE AVERAGES AND EXTREMES                     {stn_name}, ARKANSAS\\n')\n",
    "    f.write(table_sep)\n",
    "    f.write('             AVERAGE TEMPERATURES             |            TEMPERATURE EXTREMES\\n')\n",
    "    f.write('MONTH     HIGH     LOW     MONTHLY     DFN    |    MAX      DATE(S)         MIN      DATE(S)\\n')\n",
    "    f.write(table_sep)\n",
    "\n",
    "    # order is as follows: month, avg max, avg min, avg mean, avg dfn, max, max dates, min, min dates\n",
    "    for m, avgmx, avgmn, avgt, dfn, mx, mxdt, mn, mndt in zip(\n",
    "                                                              months, \n",
    "                                                              avg_high_temps, avg_low_temps, avg_temps, avg_temps_dfn,\n",
    "                                                              high_temps, high_temp_dates,\n",
    "                                                              low_temps, low_temp_dates\n",
    "                                                              ):\n",
    "        # do some formatting here...\n",
    "        # start with constants for certain spaces in the sequence\n",
    "        space1 = space*4 # the space between the dfn, and the | separator\n",
    "        space2 = space*7 # the space between the monthly high temp, and high temp dates\n",
    "        space3 = space*14 # the space b/w the max temp dates, and the monthly min temp\n",
    "        space4 = space*7 # the space b/w the min temp, and min temp dates\n",
    "\n",
    "        # format the dfn spacing and positive dfn's\n",
    "        if dfn >= 10.0 or dfn <= -10.0:\n",
    "            space1 = space*3\n",
    "\n",
    "        if dfn > 0.0:\n",
    "            dfn = f'+{dfn}'\n",
    "\n",
    "        # format the max temp spacing if > 100\n",
    "        if mx >= 100:\n",
    "            space2 = space*6\n",
    "\n",
    "        # format the min temp spacing if < -10\n",
    "        if mn <= -10:\n",
    "            space4 = space*6\n",
    "        \n",
    "        # format the max temp dates\n",
    "        if isinstance(mxdt, list):\n",
    "            adj = (len(mxdt)*3)-3\n",
    "            space3 = space*(14-adj)\n",
    "            mxdt = [i.split('/')[-1] for i in mxdt]\n",
    "            mxdt = \"/\".join(sorted(mxdt, key = int)) # sort the days in ascending order\n",
    "        \n",
    "        else:\n",
    "            mxdt = mxdt.split('/')[-1]\n",
    "\n",
    "        # format the min temp dates\n",
    "        if isinstance(mndt, list):\n",
    "            mndt = [i.split('/')[-1] for i in mndt]\n",
    "            mndt = \"/\".join(sorted(mndt, key = int)) # sort the days in ascending order\n",
    "        else:\n",
    "            mndt = mndt.split('/')[-1]                    \n",
    "        \n",
    "        f.write(f'{m}       {avgmx}    {avgmn}     {avgt}       {dfn}{space1}|    {mx}{space2}{mxdt}{space3}{mn}{space4}{mndt}\\n')\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # next add in the annual summary data\n",
    "    f.write(table_sep) # add a table separator\n",
    "\n",
    "    # constant space values we will need to adjust \n",
    "    space1 = space*4 # space b/w avg dfn and the | separator\n",
    "    space2 = space*7 # space b/w the yearly max temp and the yearly max temp dates \n",
    "    space3 = space*10 # space b/w the yearly max temp dates and the yearly min\n",
    "    space4 = space*7 # space b/w the yearly min and yearly min dates\n",
    "    \n",
    "    yrly_avgmx = np.round(np.mean(avg_high_temps),1)\n",
    "    yrly_avgmn = np.round(np.mean(avg_low_temps),1)\n",
    "    yrly_avg = np.round(np.mean(avg_temps),1)\n",
    "    \n",
    "    yrly_avg_dfn = np.round(np.sum(avg_temps_dfn), 1)\n",
    "    if yrly_avg_dfn >= 10.0 or yrly_avg_dfn <= -10.0:\n",
    "        space1 = space*3\n",
    "\n",
    "    if yrly_avg_dfn > 0.0:\n",
    "        yrly_avg_dfn = f'+{yrly_avg_dfn}'\n",
    "    \n",
    "    yrly_mx = np.max(high_temps)\n",
    "    if yrly_mx >= 100.0:\n",
    "        space2 = space*6\n",
    "        \n",
    "    yrly_mn = np.min(low_temps)\n",
    "    if yrly_mn <= -10.0:\n",
    "        space4 = space*6\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    def _find_annual_extreme_dates(temp_dates_lst, idx, max_temp = False):\n",
    "\n",
    "        '''\n",
    "        This function will parse a temp dates list with a given index and return a string of the extreme dates\n",
    "\n",
    "        temp_dates_lst : list, a list of the extreme temperature dates for a month\n",
    "        idx : int, the index value of the extreme temperature date for the year\n",
    "        max_temp : bool, default = False, if max_temp, then edit space3 variable if necessary\n",
    "\n",
    "        returns:\n",
    "        dt : str, a string of the formatted extreme temp dates\n",
    "        _space3 : str, a string of formatted spaces for the space 3 variable in the annual values line\n",
    "    \n",
    "        '''\n",
    "        \n",
    "        _space3 = space3 # we only return this for the max temp dates\n",
    "        \n",
    "        if isinstance(temp_dates_lst[idx], list):\n",
    "            if max_temp:\n",
    "                adj = (len(temp_dates_lst[idx])*3)-3\n",
    "                _space3 = space*(10-adj)\n",
    "            \n",
    "            dt = [i.split('/')[-1] for i in temp_dates_lst[idx]]\n",
    "            dt = \"/\".join(sorted(dt, key = int)), # sort the days in ascending order\n",
    "        else:\n",
    "            dt = temp_dates_lst[idx].split('/')[-1]\n",
    "\n",
    "        return dt, _space3\n",
    "\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # format the annual max temp date(s)\n",
    "    yrly_mx = np.max(high_temps)\n",
    "    idx = high_temps.index(yrly_mx)\n",
    "    \n",
    "    mxdt, space3 = _find_annual_extreme_dates(high_temp_dates, idx, max_temp = True)\n",
    "    yrly_mxdt = f'{calendar.month_name[idx+1][:3].upper()} {mxdt}'\n",
    "\n",
    "    \n",
    "    # format the annual min temp date(s)\n",
    "    yrly_mn = np.min(low_temps)\n",
    "    idx = low_temps.index(yrly_mn)\n",
    "\n",
    "    mndt, _ = _find_annual_extreme_dates(low_temp_dates, idx, max_temp = False)\n",
    "    yrly_mndt = f'{calendar.month_name[idx+1][:3].upper()} {mndt}'\n",
    "\n",
    "    # now lets write in the data\n",
    "    f.write(f'ANNUAL    {yrly_avgmx}    {yrly_avgmn}     {yrly_avg}       {yrly_avg_dfn}{space1}|    {yrly_mx}{space2}{yrly_mxdt}{space3}{yrly_mn}{space4}{yrly_mndt}\\n')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "def _make_precip_table(f, year, stn_name):\n",
    "\n",
    "    '''\n",
    "    This function will write in the annual rain summary table to the supplemental CLA product text file.\n",
    "\n",
    "    f : file, the text file that is currently open that is being written to\n",
    "    year : int, the climate year\n",
    "    stn_name : str, the three letter climate station ID\n",
    "\n",
    "    returns:\n",
    "    None\n",
    "\n",
    "    '''\n",
    "\n",
    "    # --------------------------------------------\n",
    "    def _find_numeric_suffix(myDate):\n",
    "        \n",
    "            '''\n",
    "            This function will take a string date, formatted as 'nn', e.g. '05', and assign a suffix based on the number.\n",
    "        \n",
    "            myDate : str, a date number, formatted as 'nn', e.g. '05'\n",
    "        \n",
    "            returns:\n",
    "            myDate : str, formatted as 'nnTH', 'nnST', 'nnND', 'nnRD'\n",
    "        \n",
    "            '''\n",
    "            \n",
    "            date_suffix = [\"TH\", \"ST\", \"ND\", \"RD\"]\n",
    "        \n",
    "            if int(myDate) % 10 in [1, 2, 3] and int(myDate) not in [11, 12, 13]:\n",
    "                return f'{myDate}{date_suffix[int(myDate) % 10]}'\n",
    "            else:\n",
    "                return f'{myDate}{date_suffix[0]}'\n",
    "\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # add table headers and column information\n",
    "    \n",
    "    f.write(f'\\n\\n{year} RAINFALL, DEPARTURES, AND EXTREMES                    {stn_name}, ARKANSAS\\n')\n",
    "    f.write(table_sep)\n",
    "    f.write('MONTH        RAINFALL       DFN               MAX/CALENDAR DAY            MAX/24 HOURS\\n')\n",
    "    f.write(table_sep)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # now lets compile and organize the data\n",
    "    # put together the data for iterating quickly\n",
    "    months = [calendar.month_name[i][:3].upper() for i in range(1,13)]\n",
    "\n",
    "    precip = [data_dict[m]['monthly_rain_and_dfn'][0] for m in months]\n",
    "    precip_dfn = [data_dict[m]['monthly_rain_and_dfn'][1] for m in months]\n",
    "    \n",
    "    precip_mx_clndr = [data_dict[m]['max_clndr_24hr_rain'][0] for m in months]\n",
    "    precip_mx_clndr_dates = [data_dict[m]['max_clndr_24hr_rain'][1] for m in months]\n",
    "\n",
    "    precip_mx_storm_total = [data_dict[m]['max_clndr_24hr_rain'][2] for m in months]\n",
    "    precip_mx_storm_total_dates = [data_dict[m]['max_clndr_24hr_rain'][3] for m in months]\n",
    "\n",
    "    # for loop begins\n",
    "    for m, pcp, dfn, pcp_mx_clndr, pcp_mx_clndr_dates, pcp_mx_storm_total, pcp_mx_storm_total_dates in zip(\n",
    "                                                            months,\n",
    "                                                            precip, precip_dfn,\n",
    "                                                            precip_mx_clndr, precip_mx_clndr_dates,\n",
    "                                                            precip_mx_storm_total, precip_mx_storm_total_dates\n",
    "                                                            ):\n",
    "        # --------------------------------------------\n",
    "        # lets do some formatting here\n",
    "        # start with constants for certain spaces in the sequence\n",
    "        space1 = space*10 # the space b/w the precip and the departure\n",
    "        space2 = space*14 # the space b/w the precip dfn and the precip calendar day max\n",
    "        space3 = space*19 # space b/w precip calendar day max date and the max precip storm total\n",
    "\n",
    "        # edit space 1 if monthly precip is greater than 10 inches\n",
    "        if pcp >= 10.00:\n",
    "            space1 = space*9\n",
    "\n",
    "        # edit space 2 if monthly precip dfn is >= 10.0 or <= -10.0\n",
    "        if dfn >= 10.0 or dfn <= -10.0:\n",
    "            space2 = space*12 \n",
    "\n",
    "        # assign a sign to dfn if it is positive\n",
    "        if dfn >= 0.0:\n",
    "            dfn = f'+{dfn:.2f}'\n",
    "            \n",
    "        # --------------------------------------------\n",
    "        # lets format the max calendar day rainfall dates here...\n",
    "        #for date in pcp_mx_clndr_dates:\n",
    "        bdt = list(filter(None, (pcp_mx_clndr_dates.split('TO')[0].split(' '))))[0]\n",
    "        edt = list(filter(None, (pcp_mx_clndr_dates.split('TO')[-1].split(' '))))[0]\n",
    "    \n",
    "        # if the dates are the same, then format for one day\n",
    "        if bdt == edt:\n",
    "            clndr_mxdt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "\n",
    "        # if the dates are not the same, then format for multiple dates\n",
    "        elif bdt != edt:\n",
    "            bdt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "            edt = _find_numeric_suffix(edt.split('/')[-1])\n",
    "            clndr_mxdt = f'{bdt}-{edt}' \n",
    "            space3 = space*14\n",
    "\n",
    "        # --------------------------------------------\n",
    "        # lets format the max storm total rainfall dates here...\n",
    "        bdt = list(filter(None, (pcp_mx_storm_total_dates.split('TO')[0].split(' '))))[0]\n",
    "        edt = list(filter(None, (pcp_mx_storm_total_dates.split('TO')[-1].split(' '))))[0]\n",
    "    \n",
    "        # if the dates are the same, then format for one day\n",
    "        if bdt == edt:\n",
    "            stormtotal_mxdt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "            \n",
    "        # if the dates are not the same, then format for multiple dates\n",
    "        elif bdt != edt:\n",
    "            bdt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "            edt = _find_numeric_suffix(edt.split('/')[-1])\n",
    "            stormtotal_mxdt = f'{bdt}-{edt}'\n",
    "\n",
    "        # write in the line of monthly data\n",
    "        f.write(f'{m}          {pcp:.2f}{space1}{dfn}{space2}{pcp_mx_clndr:.2f}/{clndr_mxdt}{space3}{pcp_mx_storm_total:.2f}/{stormtotal_mxdt}\\n')\n",
    "        # end of for loop\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # constant space values that may be edited based on the data\n",
    "    space1 = space*14 # space b/w yearly dfn, and yrly calendar day max precip\n",
    "    space2 = space*17 # space b/w yearly calendar day max precip date, and yearly daily max storm total precip value\n",
    "    \n",
    "    # now lets add the annual data\n",
    "    yrly_rain = np.round(np.sum(precip),2)\n",
    "    yrly_dfn = np.round(np.sum(precip_dfn),2)\n",
    "\n",
    "    # adjust space1 if yearly precip dfn is >= 10.0 or <= -10.0\n",
    "    if yrly_dfn >= 10.0 or yrly_dfn <= -10.0:\n",
    "        space1 = space*13\n",
    "    \n",
    "    # if the yrly precip dfn is >= 0.0, then assign a positive sign in the string\n",
    "    if yrly_dfn >= 0.0:\n",
    "        yrly_dfn = f'+{yrly_dfn}'\n",
    "\n",
    "    # get the max calendar day and storm total precip values\n",
    "    # mx_clndr_pcp = np.max(precip_mx_clndr)\n",
    "    # mx_stormtotal_pcp = np.max(precip_mx_storm_total)\n",
    "\n",
    "    # need to format the annual precip extreme dates...\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    def _find_annual_extreme_dates(pcp_dates_lst, idx, clndr_day_max = False): \n",
    "    \n",
    "        '''\n",
    "        This function will parse a precip dates list with a given index and return a string of the extreme dates\n",
    "        \n",
    "        pcp_dates_lst : list, a list of the extreme precip dates for a month\n",
    "        idx : int, the index value of the extreme precip date for the year\n",
    "        clndr_day_max : bool, default = False, if clndr_day_max, then edit space2 variable if necessary\n",
    "        \n",
    "        returns:\n",
    "        yrly_mxdt : str, a string of the formatted extreme precip dates\n",
    "        _space2 : str, a string of formatted spaces for the space 2 variable in the annual values line\n",
    "        \n",
    "        '''\n",
    "        _space2 = space2 # we only edit this for the calendar day max precip date, if it is two dates\n",
    "        \n",
    "        bdt = list(filter(None, (pcp_dates_lst[idx].split('TO')[0].split(' '))))[0]\n",
    "        edt = list(filter(None, (pcp_dates_lst[idx].split('TO')[-1].split(' '))))[0]\n",
    "        \n",
    "        if bdt == edt:\n",
    "            yrly_mxdt = bdt.split('/')[-1]\n",
    "        \n",
    "        elif bdt != edt:\n",
    "            bdt = bdt.split('/')[-1]\n",
    "            edt = edt.split('/')[-1]\n",
    "            yrly_mxdt = f'{bdt}-{edt}'\n",
    "            \n",
    "            if clndr_day_max:\n",
    "                _space2 = space*14\n",
    "                \n",
    "        return yrly_mxdt, _space2\n",
    "\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # yearly calendar day max precip date\n",
    "    clndr_pcp_mx = np.max(precip_mx_clndr)\n",
    "    idx = precip_mx_clndr.index(clndr_pcp_mx) # index value of the calendar day max precip\n",
    "\n",
    "    clndr_max_pcp_dt, space2 = _find_annual_extreme_dates(precip_mx_clndr_dates, idx, clndr_day_max = True)\n",
    "    yrly_clndr_pcp_mx = f'{calendar.month_name[idx+1][:3].upper()} {clndr_max_pcp_dt}'\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    \n",
    "    # yearly daily storm total max precip date\n",
    "    storm_total_pcp_mx = np.max(precip_mx_storm_total)\n",
    "    idx = precip_mx_storm_total.index(storm_total_pcp_mx)\n",
    "    \n",
    "    storm_total_pcp_max_dt, _ = _find_annual_extreme_dates(precip_mx_storm_total_dates, idx, clndr_day_max = False)\n",
    "    yrly_storm_total_pcp_max_dt = f'{calendar.month_name[idx+1][:3].upper()} {storm_total_pcp_max_dt}'\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # write in the annual precip summary data\n",
    "    f.write(table_sep)\n",
    "    f.write(f'ANNUAL       {yrly_rain}         {yrly_dfn}{space1}{clndr_pcp_mx}/{yrly_clndr_pcp_mx}{space2}{storm_total_pcp_mx}/{yrly_storm_total_pcp_max_dt}\\n')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "def _make_snow_table(f, year, stn_name):\n",
    "\n",
    "    '''\n",
    "    This function will write in the annual snow summary table to the supplemental CLA product text file.\n",
    "\n",
    "    f : file, the text file that is currently open that is being written to\n",
    "    year : int, the climate year\n",
    "    stn_name : str, the three letter climate station ID\n",
    "\n",
    "    returns:\n",
    "    None\n",
    "\n",
    "    '''\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # add table headers and column information\n",
    "\n",
    "    f.write(f'\\n\\n{year} SNOWFALL, DEPARTURES, AND EXTREMES                    {stn_name}, ARKANSAS\\n')\n",
    "    f.write(table_sep)\n",
    "    f.write('MONTH   SNOW      DFN       MAX/CALENDAR DAY       MAX/24 HOUR       GREATEST DEPTH/DATE\\n')\n",
    "    f.write(table_sep)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # now lets compile and organize the data\n",
    "    # put together the data for iterating quickly\n",
    "    #months = [calendar.month_name[i][:3].upper() for i in range(1,13)]\n",
    "    snow_months = ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC'] # these are the months we need for the snow table summary\n",
    "    \n",
    "    # we need to parse the months real quickly to just snow months\n",
    "    #months = [m for m in months if m in snow_months]\n",
    "\n",
    "    snow = [data_dict[m]['monthly_snow_sdepth_dfn'][0] for m in months if m in snow_months]\n",
    "    snow_dfn = [data_dict[m]['monthly_snow_sdepth_dfn'][1] for m in months if m in snow_months]\n",
    "    \n",
    "    mx_sdepth = [data_dict[m]['monthly_snow_sdepth_dfn'][2] for m in months if m in snow_months]\n",
    "    mx_sdepth_dt = [data_dict[m]['monthly_snow_sdepth_dfn'][3] for m in months if m in snow_months]\n",
    "    \n",
    "    mx_24hr_snow = [data_dict[m]['max_clndr_24hr_snow'][0] for m in months if m in snow_months]\n",
    "    mx_24hr_snow_dt = [data_dict[m]['max_clndr_24hr_snow'][1] for m in months if m in snow_months]    \n",
    "\n",
    "    # for loop begins\n",
    "    for m, sn, dfn, mx_sd, mx_sd_dt, mx_24hr_sn, mx_24hr_sn_dt in zip(\n",
    "                                                                snow_months,\n",
    "                                                                snow, snow_dfn,\n",
    "                                                                mx_sdepth, mx_sdepth_dt,\n",
    "                                                                mx_24hr_snow, mx_24hr_snow_dt\n",
    "                                                                  ):\n",
    "        # constant space values that may need to be edited\n",
    "        space1 = space*6 # space b/w the monthly snow, and the dfn\n",
    "        space2 = space*7 # space b/w the dfn and the calendar day max snow/date\n",
    "        space3 = space*20 # space b/w the calendar day max snow/date and the 24 hr max snow date\n",
    "        space4 = space*15 # space b/w 24 hour max, and \n",
    "        \n",
    "        # lets do some formatting here\n",
    "        # account for when there is trace monthly snow\n",
    "        if sn == 'T':\n",
    "            sn = 'T  '\n",
    "        \n",
    "        # edit space1 when snow is >= 10.0\n",
    "        if isinstance(sn, float) and sn >= 10.0: # used isinstance to keep value error from popping up when making comparison\n",
    "            space1 = space*5\n",
    "\n",
    "        # adjust dfn parameters\n",
    "        if dfn >= 10.0: # snow dfn will never less than 10 inches for our climate sites\n",
    "            dfn = f'+{dfn}'\n",
    "            space2 = space*6\n",
    "        \n",
    "        elif dfn == 0.0:\n",
    "            dfn = f' {dfn}'\n",
    "\n",
    "        # --------------------------------------------\n",
    "        # lets format the max calendar day and 24 hr snowfall dates here...\n",
    "\n",
    "        if isinstance(mx_24hr_sn_dt, str): # if no max snowfall value, then date values are set to nan, so check for this\n",
    "        \n",
    "            bdt = list(filter(None, (mx_24hr_sn_dt.split('TO')[0].split(' '))))[0]\n",
    "            edt = list(filter(None, (mx_24hr_sn_dt.split('TO')[-1].split(' '))))[0]\n",
    "\n",
    "            # if the dates are the same, then format for one day\n",
    "            if bdt == edt:\n",
    "                mx_24hr_sn_dt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "\n",
    "                if isinstance(mx_24hr_sn, float) and mx_24hr_sn >= 10.0:\n",
    "                    space3 = space*9\n",
    "                    space4 = space*6\n",
    "                    \n",
    "                elif isinstance(mx_24hr_sn, float) and mx_24hr_sn <= 10.0:\n",
    "                    space3 = space*15\n",
    "                    space4 = space*10\n",
    "                    \n",
    "                elif mx_24hr_sn == 'T':\n",
    "                    space3 = space*17\n",
    "                    space4 = space*12\n",
    "                    \n",
    "            # if the dates are not the same, then format for multiple dates\n",
    "            elif bdt != edt:\n",
    "                bdt = _find_numeric_suffix(bdt.split('/')[-1])\n",
    "                edt = _find_numeric_suffix(edt.split('/')[-1])\n",
    "                mx_24hr_sn_dt = f'{bdt}-{edt}'\n",
    "\n",
    "                if isinstance(mx_24hr_sn, float) and mx_24hr_sn >= 10.0:\n",
    "                    space3 = space*9\n",
    "                    space4 = space*4\n",
    "\n",
    "                elif isinstance(mx_24hr_sn, float) and mx_24hr_sn <= 10.0:\n",
    "                    space3 = space*10\n",
    "                    space4 = space*5\n",
    "\n",
    "                elif mx_24hr_sn == 'T':\n",
    "                    space3 = space*11\n",
    "                    space4 = space*6\n",
    "\n",
    "            # format the max calendar day, and 24 hour snow fall values and dates (if applicable)\n",
    "            mx_24hr_sn = f'{mx_24hr_sn}/{mx_24hr_sn_dt}'\n",
    "\n",
    "        # lets format the max snow depth/dates\n",
    "        if mx_sd > 0.0:\n",
    "            dt = _find_numeric_suffix(mx_sd_dt.split('/')[-1])\n",
    "            mx_sd = f'{int(mx_sd)}/{dt}'\n",
    "\n",
    "        else:\n",
    "            mx_sd = '0'\n",
    "        \n",
    "        f.write(f'{m}     {sn}{space1}{dfn}{space2}{mx_24hr_sn}{space3}{mx_24hr_sn}{space4}{mx_sd}\\n')\n",
    "        # end of for loop\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # now lets add the annual data max values at the bottom of the table\n",
    "\n",
    "    # constant space values\n",
    "    space1 = space*6 # space b/w the yearly snow and the yearly dfn\n",
    "    space2 = space*7 # space b/w the yearly snow dfn and the calendar day max snow value/date\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # get the annual snowfall total\n",
    "    sn_filtered = [s for s in snow if s != 'T'] # filter out trace values\n",
    "    \n",
    "    # if the two lists are equal after filtering, then we filtered no T's\n",
    "    if len(snow) == len(sn_filtered):\n",
    "        yrly_sn = np.sum(sn_filtered)\n",
    "    \n",
    "    # if the two lists are not equal after filtering, then we filtered T's out...\n",
    "    elif len(snow) != len(sn_filtered):\n",
    "        if np.sum(sn_filtered) == 0.0:\n",
    "            yrly_sn = 'T'\n",
    "    \n",
    "        elif np.sum(sn_filtered) > 0.0:\n",
    "            yrly_sn = np.sum(sn_filtered)\n",
    "\n",
    "    if isinstance(yrly_sn, float) and yrly_sn >= 10.0:\n",
    "        space1 = space*5\n",
    "        \n",
    "    # -------------------------------------------\n",
    "    # get the annual snow dfn\n",
    "    yrly_sn_dfn = np.sum(snow_dfn)\n",
    "    if yrly_sn_dfn > 10.0:\n",
    "        yrly_sn_dfn = f'+{yrly_sn_dfn}'\n",
    "        space2 = space*6\n",
    "\n",
    "    elif yrly_sn_dfn == 0.0:\n",
    "        yrly_sn_dfn = ' 0.0'\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # get the max calendar day snow value and date\n",
    "    \n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    f.write(table_sep)\n",
    "    f.write(f'ANN.    {yrly_sn}{space1}{yrly_sn_dfn}{space2}0.4  JAN 31            0.4  JAN 31          0\\n')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "def _get_station_name(pil):\n",
    "    if pil[3:] == 'LZK':\n",
    "        stn_name = 'NORTH LITTLE ROCK'\n",
    "    elif pil[3:] == 'LIT':\n",
    "        stn_name = 'LITTLE ROCK'\n",
    "    elif pil[3:] == 'HRO':\n",
    "        stn_name = 'HARRISON'\n",
    "    elif pil[3:] == 'PBF':\n",
    "        stn_name = 'PINE BLUFF'\n",
    "\n",
    "    return stn_name\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# will need to incorporate these into a function call...\n",
    "pil = 'CLMLZK'\n",
    "year = 2021\n",
    "\n",
    "stn_name = _get_station_name(pil)\n",
    "\n",
    "# a constant that will be used multiple times\n",
    "table_sep = '--------------------------------------------------------------------------------------------\\n'\n",
    "space = ' '\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# here we're actually writing the text file\n",
    "with open(f'./test_supplemental_CLA{pil[3:]}_data.txt', 'w') as f:\n",
    "\n",
    "    f.write(f'SUPPLEMENTAL ANNUAL CLIMATE DATA FOR {stn_name}\\n')\n",
    "    f.write('\\n(DFN = DEPARTURE FROM NORMAL)\\n')\n",
    "    \n",
    "    # first up, the annual temperature summary table\n",
    "    _make_temp_table(f, year, stn_name)\n",
    "\n",
    "    # next, write the annual precip summary table\n",
    "    _make_precip_table(f, year, stn_name)\n",
    "\n",
    "    # next, write the annual snow summary table\n",
    "    _make_snow_table(f, year, stn_name)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ce4c0876-d88c-49d4-8bdb-545f1ca29073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write our dictionary to a text file, so we can operate easily in pycharm without having to re acquire the data everytime...\n",
    "with open('./2021_LZK_Annual_Summary.txt', 'w') as f:\n",
    "    f.write(json.dumps(data_dict))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "820e17ef-fa21-4441-86fc-d0075dca7fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./2021_LZK_Annual_Summary.txt', 'r') as f:\n",
    "    json_str = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "_new_data_dict = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed925694-5c4b-4edd-a952-0f54c99f4175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7c2ae938-84a0-43c3-aecc-040cffdcb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp = [data_dict[m]['monthly_rain_and_dfn'][0] for m in months]\n",
    "pcp_dfn = [data_dict[m]['monthly_rain_and_dfn'][1] for m in months]\n",
    "\n",
    "pcp_mx_clndr = [data_dict[m]['max_clndr_24hr_rain'][0] for m in months]\n",
    "pcp_mx_clndr_dates = [data_dict[m]['max_clndr_24hr_rain'][1] for m in months]\n",
    "\n",
    "precip_mx_storm_total = [data_dict[m]['max_clndr_24hr_rain'][2] for m in months]\n",
    "precip_mx_storm_total_dates = [data_dict[m]['max_clndr_24hr_rain'][3] for m in months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "329bbc36-f6f5-4115-9151-662ce74bb076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 18.7, 'T', 0.0, 0.0, 0.0, 0.0],\n",
       " [-1.7, 16.9, -0.4, 0.0, 0.0, -0.1, -0.6],\n",
       " [0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [nan, '02/18', nan, nan, nan, nan, nan],\n",
       " ['T', 10.9, 'T', 0.0, 0.0, 0.0, 0.0],\n",
       " ['01/15 TO 01/15', '02/14 TO 02/15', '03/31 TO 03/31', nan, nan, nan, nan])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow = [data_dict[m]['monthly_snow_sdepth_dfn'][0] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "snow_dfn = [data_dict[m]['monthly_snow_sdepth_dfn'][1] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "\n",
    "mx_sdepth = [data_dict[m]['monthly_snow_sdepth_dfn'][2] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "mx_sdepth_dt = [data_dict[m]['monthly_snow_sdepth_dfn'][3] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "\n",
    "mx_24hr_snow = [data_dict[m]['max_clndr_24hr_snow'][0] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "mx_24hr_snow_dt = [data_dict[m]['max_clndr_24hr_snow'][1] for m in months if m in ['JAN', 'FEB', 'MAR', 'APR', 'OCT', 'NOV', 'DEC']]\n",
    "\n",
    "snow, snow_dfn, mx_sdepth, mx_sdepth_dt, mx_24hr_snow, mx_24hr_snow_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d20022db-775f-4012-993d-198269a9c22f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[450], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msnow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "list(filter('T', (snow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "1251c159-e3aa-41d5-92a9-d14eceac9a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[448], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m snow_filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m snow_filtered\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "snow_filtered = list(filter('T', snow))\n",
    "snow_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "8bdc532f-0b9e-4731-8832-14efdcee3f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.7"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_filtered = [s for s in snow if s != 'T'] # filter out trace values\n",
    "\n",
    "# if the two lists are equal after filtering, then we filtered no T's\n",
    "if len(snow) == len(sn_filtered):\n",
    "    yrly_sn = np.sum(sn_filtered)\n",
    "\n",
    "# if the two lists are not equal after filtering, then we filtered T's out...\n",
    "elif len(snow) != len(sn_filtered):\n",
    "    if np.sum(sn_filtered) == 0.0:\n",
    "        yrly_sn = 'T'\n",
    "\n",
    "    elif np.sum(sn_filtered) > 0.0:\n",
    "        yrly_sn = np.sum(sn_filtered)\n",
    "\n",
    "yrly_sn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf7bc5-b112-4a76-8079-ca36b551bad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5470e-200f-4553-a47c-b962e38ad27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "649f32fa-5bd0-4996-9de5-05d39aad74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bla bla bla ceci est une phrase beaucoup trop longue pour ce que je', \"doit réellement dire, en fait je peux même dire qu'elle ne sert a\", 'rien, mais du coup je doit quand même la tester']\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "#phrase = \"bla bla bla ceci est une phrase beaucoup trop longue pour ce que je doit réellement dire, en fait je peux même dire qu'elle ne sert a rien, mais du coup je doit quand même la tester\"\n",
    "phrase = 'THE LOWEST YEARLY MINIMUM TEMPERATURE OF 18 DEGREES OCCURRED ON JAN 14TH, 31ST, AND MAR 19TH, WHICH WAS THE WARMEST LOW TEMPERATURE SINCE RECORD KEEPING BEGAN IN 1892 OR PUT ANOTHER WAY, THE 1ST HOTTEST MINIMUM TEMPERATURE OF ANY YEAR. THE NEW LOW OF 18 DEGREES SURPASSES THE PREVIOUS RECORD OF 16 DEGREES SET IN 1987.'\n",
    "\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width = 69) # this will be our wrapper function, limits characters to 69\n",
    "\n",
    "#print(wrap_list)\n",
    "\n",
    "with open(\"test__.txt\", \"w\") as f:\n",
    "    f.write(wrapper.fill(phrase)) # wrapper.fill automatically starts a new line when it wraps (adds '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59dd33-12e8-47bc-adcf-c440b24f6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be8e50-ce1b-4b84-aeaf-0a9935932a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6304c-7ac1-4071-a8cc-8e1f2d400ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precip_data(monthly_precip_data, monthly_snow_data, month):\n",
    "\n",
    "    '''\n",
    "    This function will parse the precip text info from the API url, and will append precip and snow data\n",
    "    to the main working dictionary.\n",
    "\n",
    "    monthly_precip_data : str, the parsed monthly precip data as a string\n",
    "    monthly_snow_data : str, the parsed monthly snow data as a string\n",
    "    month : int, the month as an integer\n",
    "\n",
    "    returns: \n",
    "    None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Helper Sub-functions of the main function\n",
    "    # --------------------------------------------------------\n",
    "    def _check_record(param):\n",
    "        if 'R' in param:\n",
    "            return param.split('R')[0]\n",
    "        else:\n",
    "            return param\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    def _check_missing_snow(param, month):\n",
    "        try:\n",
    "            data_dict[month]['monthly_snow_sdepth_and_dfn'].append(float(param)) # monthly total\n",
    "        \n",
    "        except ValueError:\n",
    "            data_dict[month]['monthly_snow_sdepth_and_dfn'].append(0.0)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    \n",
    "    # convert the integer month to the three letter month name\n",
    "    month = calendar.month_name[month][:3].upper()\n",
    "\n",
    "\n",
    "    \n",
    "    # ---- Monthly Rain Data -----\n",
    "    monthly_total_rain = _check_record(float(list(filter(None, (monthly_precip_data.split(' '))))[0])) # monthly total rain\n",
    "    monthly_rain_dfn = _check_record(float(list(filter(None, (monthly_precip_data.split(' '))))[2]))\n",
    "    \n",
    "    # add the monthly precip total and dfn\n",
    "    data_dict[month]['monthly_rain_and_dfn'].append(monthly_total_rain) # monthly total\n",
    "    data_dict[month]['monthly_rain_and_dfn'].append(monthly_rain_dfn) # monthly dfn\n",
    "\n",
    "    # now lets get the calendar max, 24 hr max values and dates for rain\n",
    "    for idx, line in enumerate(monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].splitlines()):\n",
    "        if idx == 0:\n",
    "            max_clndr_rain = float(list(filter(None, (line.split(' ')))[0]))\n",
    "            max_clndr_rain_dates = \" \".join(list(filter(None, (line.split(' ')))[1:]))\n",
    "\n",
    "        elif idx == 1:\n",
    "            max_stormtotal_rain = float(list(filter(None, (line.split(' ')))[-1]))\n",
    "        \n",
    "    #data_dict[month]['max_clndr_24hr_rain'].append(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].split(' '))))[0]) # 24 hr max (calendar day max)\n",
    "    #data_dict[month]['max_clndr_24hr_rain'].append(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].split(' '))))[1:4]) # 24 hr max dates\n",
    "\n",
    "    # 24 hour (calendar day max) rainfall data\n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_clndr_rain) # 24 hr max (calendar day max)\n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_clndr_rain_dates) # 24 hr max dates\n",
    "    \n",
    "    # storm total rain data\n",
    "    #data_dict[month]['max_clndr_24hr_rain'].append(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].split(' '))))[7]) # storm total \n",
    "    #data_dict[month]['max_clndr_24hr_rain'].append(list(filter(None, (monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].split(' '))))[1:4]) # 24 hr max dates (treat as same for now)\n",
    "    \n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_stormtotal_rain) # max storm total \n",
    "    data_dict[month]['max_clndr_24hr_rain'].append(max_clndr_rain_dates) # max storm total dates (set equal to 24 hr max for now)\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---- Monthly Snow Data ----\n",
    "    # add the monthly snow total and dfn\n",
    "    monthly_total_snow = _check_record(list(filter(None, (monthly_snow_data.split(' '))))[0]) # monthly total snow\n",
    "    monthly_grtst_sdepth = _check_record(list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n SNOW DEPTH')[-1].splitlines()[0].split(' '))))[0]) # monthly greatest snow depth\n",
    "    monthly_snow_dfn = _check_record(list(filter(None, (monthly_snow_data.split(' '))))[2]) # monthly total snow dfn\n",
    "\n",
    "    # for the non winter months, monthly snow may just be set to 'MM' in the CLM product\n",
    "    _check_missing_snow(monthly_total_snow, month) # this will add the monthly total snow\n",
    "    _check_missing_snow(monthly_grtst_sdepth, month) # this will add the greatest monthly snow depth\n",
    "    _check_missing_snow(monthly_snow_dfn, month) # this will add the monthly total snow dfn   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54013330-91f5-482f-b56e-04cb51226cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81\n"
     ]
    }
   ],
   "source": [
    "for idx, line in enumerate(monthly_precip_data.split('\\nGREATEST\\n 24 HR. TOTAL')[-1].splitlines()):\n",
    "    #print(line.split(' '))\n",
    "    # if idx == 0:\n",
    "    #     print(\" \".join(list(filter(None, (line.split(' '))))[1:]))\n",
    "    if idx == 1:\n",
    "        print(list(filter(None, (line.split(' '))))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14b01d6e-f2d3-4f35-b1c3-f849d678a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['       14R  02/18                                           ',\n",
       " ' 24 HR TOTAL    10.9R  02/14 TO 02/15                0.3  02/20 TO 02/20']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_snow_data.split('\\nGREATEST\\n SNOW DEPTH')[-1].splitlines()\n",
    "\n",
    "monthly_sdepth = _check_record(list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n SNOW DEPTH')[-1].splitlines()[0].split(' '))))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71881c52-f038-4b13-8be8-a167c0195842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14R'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(None, (monthly_snow_data.split('\\nGREATEST\\n SNOW DEPTH')[-1].splitlines()[0].split(' '))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b94576-b116-41e7-b3ca-a6e274a25432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'          18.7R               1.8    16.9      0.3               \\n LIQUID EQUIV   1.90               0.20    1.70     0.03               \\nSINCE 7/1       18.8                4.0    14.8       MM               \\n LIQUID 7/1     1.88               0.00    1.88       MM               \\nSNOWDEPTH AVG.     2                                                   \\nDAYS >= TRACE      6                1.2     4.8        3               \\nDAYS >= 1.0        3                                   0               \\nGREATEST\\n SNOW DEPTH       14R  02/18                                           \\n 24 HR TOTAL    10.9R  02/14 TO 02/15                0.3  02/20 TO 02/20\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_snow_data = text.split('SNOWFALL (INCHES)')[-1].split('\\nTOTALS')[-1].split('\\nDEGREE DAYS')[0]\n",
    "monthly_snow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f3efe5-e892-4cc7-9600-cff09b4dc6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.5, 3.96)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(list(filter(None, (monthly_precip_data.split(' '))))[0]), float(list(filter(None, (monthly_precip_data.split(' '))))[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "108b6da0-2bd5-4dd8-9d54-c7f4fab18fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we were working with the xmacis API to obtain data, we have working code to get annual avg data and departure from normal,\n",
    "now we need some logic to compare a yearly value \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def get_annual_xmacis_data(station):\n",
    "\n",
    "    # a dictionary that contains the json syntax to the xmacis api, that will return yearly avg values for the por, and the departures from normal\n",
    "    json_dict = {\n",
    "        'lit' : '{\"sid\":\"LITthr\",\"sdate\":\"por\",\"edate\":\"por\",\"output\":\"json\",\"elems\":[{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"normal\":\"departure\",\"maxmissing\":\"7\",\"prec\":1}],\"output\":\"json\"}',\n",
    "        'lzk' : '{\"sid\":\"LZKthr\",\"sdate\":\"por\",\"edate\":\"por\",\"output\":\"json\",\"elems\":[{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"normal\":\"departure\",\"maxmissing\":\"7\",\"prec\":1}],\"output\":\"json\"}',\n",
    "        'hro' : '{\"sid\":\"HROthr\",\"sdate\":\"por\",\"edate\":\"por\",\"output\":\"json\",\"elems\":[{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":0},{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":0},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"normal\":\"departure\",\"maxmissing\":\"7\",\"prec\":1}],\"output\":\"json\"}',\n",
    "        'pbf' : '{\"sid\":\"PBFthr\",\"sdate\":\"por\",\"edate\":\"por\",\"output\":\"json\",\"elems\":[{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"maxt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"mint\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"avgt\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"mean\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"pcpn\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"normal\":\"departure\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"maxmissing\":\"7\",\"prec\":1},{\"name\":\"snow\",\"interval\":\"yly\",\"duration\":1,\"reduce\":\"sum\",\"normal\":\"departure\",\"maxmissing\":\"7\",\"prec\":1}],\"output\":\"json\"}'\n",
    "    }\n",
    "\n",
    "    json_text = json_dict[station]\n",
    "    \n",
    "    # the xmacis api server for station data\n",
    "    url = f\"https://data.rcc-acis.org/StnData?params={json_text}\"\n",
    "    \n",
    "    # A GET request to the API\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "\n",
    "data = get_annual_xmacis_data('hro')\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# this will take the json dictionary from the api, and create lists of lists for each annual avg parameter\n",
    "maxt = [item[:3] for item in data['data']]\n",
    "mint = []\n",
    "avgt = []\n",
    "pcpn = []\n",
    "snow = []\n",
    "\n",
    "for item in data['data']:\n",
    "\n",
    "    mint.append([item[0], item[3], item[4]])\n",
    "    avgt.append([item[0], item[5], item[6]])\n",
    "    pcpn.append([item[0], item[7], item[8]])\n",
    "    snow.append([item[0], item[9], item[10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "13f97dd9-e4ab-4d94-96b8-c91ab341eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_annual_temps(temps, mintemps = False):\n",
    "\n",
    "    '''\n",
    "    This function will sort a list of annual avg temp values, and delete missing years\n",
    "\n",
    "    temps : list of lists, a list of lists of annual temps for a station, including the year, avg value, and departure from normal\n",
    "    mintemps : boolean, default set to False, if True, then returned order will be reversed to represent the coldest temps at the top\n",
    "\n",
    "    returns:\n",
    "    param_filtered : a sorted and filtered list of annual avg temps\n",
    "\n",
    "    '''\n",
    "    \n",
    "    index = [1, 2]\n",
    "\n",
    "    # for precip parameters this converts the values that are not missing or trace to floats\n",
    "    param_filtered =[\n",
    "            [np.float64(val) if i in index and val not in ['M'] else val for i, val in enumerate(subl)] \n",
    "            for subl in temps\n",
    "            ]\n",
    "    \n",
    "    # now lets convert missings to nan, nans arrise from the 7 missing days in a year threshold\n",
    "    param_filtered = [\n",
    "            [np.nan if i in index and val == 'M' else val for i, val in enumerate(subl)] \n",
    "            for subl in param_filtered\n",
    "            ]\n",
    "\n",
    "    # now convert the years to integers\n",
    "    index = [0]\n",
    "    \n",
    "    param_filtered =[\n",
    "        [int(val) if i in index and val not in ['M'] else val for i, val in enumerate(subl)] \n",
    "        for subl in param_filtered\n",
    "        ]\n",
    "    \n",
    "    # this will remove the nan values for sorting the data\n",
    "    param_filtered = [item for item in param_filtered if item[1] is not np.nan]\n",
    "    \n",
    "    # this will create a sorted list, with the largest values first\n",
    "    if mintemps:\n",
    "        return sorted(param_filtered, key=itemgetter(1), reverse = False)\n",
    "    else:\n",
    "        return sorted(param_filtered, key=itemgetter(1), reverse = True)\n",
    "\n",
    "\n",
    "maxt_filtered = sort_annual_temps(maxt)\n",
    "mint_filtered = sort_annual_temps(mint, mintemps = True)\n",
    "avgt_filtered = sort_annual_temps(avgt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "40b3d933-127b-4f25-a1b9-b8442539493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found our year at rank 15\n",
      "The yearly average high temperature of 2023 was the 15th warmest year, and the warmest year since 2017.\n"
     ]
    }
   ],
   "source": [
    "searchyear = 2023\n",
    "\n",
    "for idx, lst in enumerate(maxt_filtered):\n",
    "    #print(idx+1, lst)\n",
    "\n",
    "    if lst[0] == searchyear:\n",
    "        rank = idx+1\n",
    "        break\n",
    "\n",
    "percentile = (rank/len(maxt_filtered))*100\n",
    "\n",
    "filtered_data = maxt_filtered[:idx]\n",
    "# calculate residules over the filtered list to find the min residual and thus, the next closest year\n",
    "res = []\n",
    "for sublst in filtered_data:\n",
    "    res.append(abs(searchyear - sublst[0]))\n",
    "\n",
    "next_closest_year = filtered_data[res.index(min(res))][0]\n",
    "\n",
    "if percentile < 50:\n",
    "    print(f'The yearly average high temperature of {searchyear} was the {rank}th warmest year, and the warmest year since {next_closest_year}.')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d9285e46-c290-4919-8b70-271e86efcdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "filtered_data\n",
    "\n",
    "res = []\n",
    "for sublst in filtered_data:\n",
    "    res.append(abs(searchyear - sublst[0]))\n",
    "\n",
    "print(res.index(min(res)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee59c5-aa33-4773-98a4-85483a17e67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "08a5b86d-0f6b-4d2b-b36e-bf952a89d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_annual_precip_value(param):\n",
    "\n",
    "    '''\n",
    "    This function will sort a list of annual total snowfall or precip values, converting Trace values to 0.005, and deleting missing years\n",
    "\n",
    "    param : list of lists, a list of lists of snowfall or precip for a station, including the year, total value, and departure from normal\n",
    "\n",
    "    returns:\n",
    "    param_filtered : a sorted and filtered list of annual param totals\n",
    "\n",
    "    '''\n",
    "    \n",
    "    index = [1, 2]\n",
    "\n",
    "    # for precip parameters this converts the values that are not missing or trace to floats\n",
    "    param_filtered =[\n",
    "            [np.float64(val) if i in index and val not in ['M', 'T'] else val for i, val in enumerate(subl)] \n",
    "            for subl in param\n",
    "            ]\n",
    "    \n",
    "    # now lets convert missings to nan, nans arrise from the 7 missing days in a year threshold\n",
    "    param_filtered = [\n",
    "            [np.nan if i in index and val == 'M' else val for i, val in enumerate(subl)] \n",
    "            for subl in param_filtered\n",
    "            ]\n",
    "    \n",
    "    # lastly lets convert trace to 0.005\n",
    "    param_filtered = [\n",
    "            [np.float64(0.005) if i in index and val == 'T' else val for i, val in enumerate(subl)] \n",
    "            for subl in param_filtered\n",
    "            ]\n",
    "\n",
    "    # now convert the years to integers\n",
    "    index = [0]\n",
    "    \n",
    "    param_filtered =[\n",
    "        [int(val) if i in index and val not in ['M'] else val for i, val in enumerate(subl)] \n",
    "        for subl in param_filtered\n",
    "        ]\n",
    "    \n",
    "    # this will remove the nan values for sorting the data\n",
    "    param_filtered = [item for item in param_filtered if item[1] is not np.nan]\n",
    "    \n",
    "    # this will create a sorted list, with the largest values first\n",
    "    return sorted(param_filtered, key=itemgetter(1), reverse = True)\n",
    "\n",
    "\n",
    "filtered_snow = sort_annual_precip_value(snow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3bd1c9-93ac-4a1e-8230-e61c1cb7b7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5b513f8e-1c94-44ed-9a39-533cac0beeda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"254 \\nCXUS54 KLZK 081205\\nCLMLZK\\n\\nCLIMATE REPORT...UPDATED WITH SUPPLEMENTAL DATA \\nNATIONAL WEATHER SERVICE LITTLE ROCK AR\\n553 AM CST SUN FEB 05 2023\\n\\n...................................\\n\\n...THE NORTH LITTLE ROCK CLIMATE SUMMARY FOR THE MONTH OF JANUARY 2023...\\n\\nCLIMATE NORMAL PERIOD 1991 TO 2020\\nCLIMATE RECORD PERIOD 1975 TO 2023\\n\\nWEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \\n                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \\n                                          NORMAL                       \\n................................................................\\nTEMPERATURE (F)\\nRECORD\\n HIGH             81   01/30/2002                                      \\n LOW              -6   01/20/1985                                      \\nHIGHEST           72   01/11         49      23       68  01/01        \\nLOWEST            24   01/31         31      -7       13  01/21        \\n                       01/14                                           \\nAVG. MAXIMUM    54.9               48.9     6.0     50.2               \\nAVG. MINIMUM    39.1               32.2     6.9     28.7               \\nMEAN            47.0               40.6     6.4     39.4               \\nDAYS MAX >= 90     0                0.0     0.0        0               \\nDAYS MAX <= 32     1                2.1    -1.1        3               \\nDAYS MIN <= 32     7               14.4    -7.4       20               \\nDAYS MIN <= 0      0                0.0     0.0        0               \\n\\nPRECIPITATION (INCHES)\\nRECORD\\n MAXIMUM        7.55   1999                                            \\n MINIMUM        0.31   2003                                            \\nTOTALS          7.50               3.54    3.96     5.13               \\nDAILY AVG.      0.24               0.11    0.13     0.17               \\nDAYS >= .01       13                9.4     3.6       MM               \\nDAYS >= .10       11                                  MM               \\nDAYS >= .50        7                                  MM               \\nDAYS >= 1.00       4                0.8     3.2       MM               \\nGREATEST\\n 24 HR. TOTAL   1.31   01/29 TO 01/29                                  \\n STORM TOTAL    1.31                                                   \\n (MM/DD(HH))                                                           \\n\\nSNOWFALL (INCHES)\\nRECORDS\\n TOTAL          12.4   1988                                            \\n 24 HR TOTAL    12.0   01/06/1988 TO 01/07/1988                        \\n SNOW DEPTH       12   01/07/1988                                      \\nTOTALS           0.4                1.0    -0.6      1.6               \\n LIQUID EQUIV   0.00               0.30   -0.30     0.20               \\nSINCE 7/1        0.6                1.7    -1.1       MM               \\n LIQUID 7/1     0.06               0.00    0.06       MM               \\nSNOWDEPTH AVG.     T                                                   \\nDAYS >= TRACE      4                0.7     3.3        5               \\nDAYS >= 1.0        0                                   1               \\nGREATEST\\n SNOW DEPTH       MM                                                   \\n 24 HR TOTAL      MM                                 1.6  01/15 TO 01/16\\n\\nDEGREE DAYS\\nHEATING TOTAL    553                758    -205      785               \\n SINCE 7/1      1791               2007    -216       MM               \\nCOOLING TOTAL      1                  0       1        0               \\n SINCE 1/1         1                  0       1       MM               \\n\\nFREEZE DATES\\nRECORD\\n EARLIEST     10/20/1989                                               \\n LATEST       04/19/1983                                               \\nEARLIEST                        11/12                                  \\nLATEST                          03/13                                  \\n................................................................\\n\\nWIND (MPH)\\nAVERAGE WIND SPEED              MM                                     \\nHIGHEST WIND SPEED/DIRECTION    MM        DATE   MM                    \\nHIGHEST GUST SPEED/DIRECTION    MM        DATE   MM                    \\n\\nSKY COVER\\nPOSSIBLE SUNSHINE (PERCENT)   MM                                       \\nAVERAGE SKY COVER             MM                                       \\nNUMBER OF DAYS FAIR            0                                       \\nNUMBER OF DAYS PC              0                                       \\nNUMBER OF DAYS CLOUDY          0                                       \\n\\n\\nWEATHER CONDITIONS. NUMBER OF DAYS WITH \\nTHUNDERSTORM              4     MIXED PRECIP               1           \\nHEAVY RAIN                5     RAIN                       7           \\nLIGHT RAIN               12     FREEZING RAIN              2           \\nLT FREEZING RAIN          2     HAIL                       0          \\nHEAVY SNOW                0     SLEET                      3          \\nFOG                       6     FOG W/VIS <= 1/4 MILE      2           \\nHAZE                      0                                           \\n\\n-  INDICATES NEGATIVE NUMBERS.\\nR  INDICATES RECORD WAS SET OR TIED.\\nMM INDICATES DATA IS MISSING.\\nT  INDICATES TRACE AMOUNT.\\n\\n&&\\n\\n.MONTHLY AVERAGES... \\nTHE AVERAGE HIGH TEMPERATURE OF 54.9 F (+6.0 F) WAS THE 5TH WARMEST \\nAVERAGE HIGH ON RECORD BEHIND 2006, 2002, 1990, AND 2012. THE \\nAVERAGE LOW TEMPERATURE OF 39.1 F (+6.9 F) WAS THE 3RD WARMEST \\nAVERAGE LOW BEHIND 2006 AND 1998. THE AVERAGE TEMPERATURE OF 47.0 F \\n(+6.4 F) TIED 2002 AS THE 3RD WARMEST ON RECORD BEHIND 2006 AND \\n1990. THE MONTHLY HIGH, LOW, AND AVERAGE TEMPERATURES WERE ALL WELL \\nABOVE THE 30-YEAR CLIMATOLOGICAL AVERAGES.\\n \\n.DAILY TEMPERATURES... \\nDAILY TEMPERATURES WERE AVERAGE ON 1 DAY.\\nDAILY TEMPERATURES WERE ABOVE AVERAGE ON 23 DAYS.\\nDAILY TEMPERATURES WERE BELOW AVERAGE ON 7 DAYS.\\n \\n.DAILY TEMPERATURE RECORDS TIED OR BROKEN DURING THE MONTH... \\nNO TEMPERATURE RECORDS WERE TIED OR BROKEN.\\n \\n.MONTHLY RAINFALL... \\nTHE MONTHLY RAINFALL TOTAL OF 7.50 INCHES WAS THE 2ND WETTEST ON \\nRECORD, ONLY TOPPED BY 1999. THE MONTHLY RAINFALL WAS 3.96 INCHES \\nABOVE AVERAGE FOR THE MONTH.\\n \\n.DAILY RAINFALL RECORDS TIED OR BROKEN DURING THE MONTH...\\nDATE    RECORD TYPE\\t        NEW RECORD        PREVIOUS RECORD \\n28TH    RAINFALL            1.05 (2023)       0.93 (1990)\\n29TH    RAINFALL            1.31 (2023)       1.09 (2001)\\n \\n.MONTHLY SNOWFALL... \\nTHE MONTHLY SNOWFALL WAS 0.4 INCHES. THIS IS 0.6 INCHES BELOW \\nAVERAGE FOR THE MONTH.\\n \\n.DAILY SNOWFALL RECORDS TIED OR BROKEN DURING THE MONTH... \\nDATE    RECORD TYPE\\t        NEW RECORD        PREVIOUS RECORD \\n24TH    SNOWFALL            T (2023)          T (1979/2000)\\n\\n$$\\n\\n69\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLZK'\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c86cb9ba-ae3d-459f-8e3c-bc27393d31a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'            47.0               40.6     6.4     39.4               \\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_high = text.split('AVG. MAXIMUM')[-1].split('AVG. MINIMUM')[0] # with this, the first value would be the monthly avg, the 3rd value would be the DFN\n",
    "avg_low = text.split('AVG. MINIMUM')[-1].split('MEAN')[0] \n",
    "\n",
    "mon_avg_temp = text.split('MEAN')[-1].split('DAYS MAX >= 90')[0]\n",
    "mon_avg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07e7b5ba-8458-467e-8754-3e7102c3e42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schema': {'fields': [{'name': 'index', 'type': 'integer'}, {'name': 'entered', 'type': 'string'}, {'name': 'pil', 'type': 'string'}, {'name': 'product_id', 'type': 'string'}, {'name': 'cccc', 'type': 'string'}, {'name': 'count', 'type': 'integer'}, {'name': 'link', 'type': 'string'}, {'name': 'text_link', 'type': 'string'}], 'primaryKey': ['index'], 'pandas_version': '1.4.0'}, 'data': [{'index': 0, 'entered': '2023-02-05T11:53:00Z', 'pil': 'CLMLIT', 'product_id': '202302051153-KLZK-CXUS54-CLMLIT', 'cccc': 'KLZK', 'count': 2, 'link': 'https://mesonet.agron.iastate.edu/p.php?pid=202302051153-KLZK-CXUS54-CLMLIT', 'text_link': 'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLIT'}]} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil=CLMLIT&date=2023-02-05'\n",
    "\n",
    "# A GET request to the API\n",
    "response = requests.get(url)\n",
    "\n",
    "# turn the request into a json, and subsequently a dictionary\n",
    "response = response.json()\n",
    "\n",
    "# convert the json to dictionary\n",
    "#response = f'[{response}]'\n",
    "#response = json.loads(response)[0]\n",
    "print(response, type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "972f099b-bc83-4fe4-8dbc-406040a08b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'entered': '2023-02-05T11:53:00Z',\n",
       " 'pil': 'CLMLIT',\n",
       " 'product_id': '202302051153-KLZK-CXUS54-CLMLIT',\n",
       " 'cccc': 'KLZK',\n",
       " 'count': 2,\n",
       " 'link': 'https://mesonet.agron.iastate.edu/p.php?pid=202302051153-KLZK-CXUS54-CLMLIT',\n",
       " 'text_link': 'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLIT'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cac6ff7e-0dd1-4144-ae2e-1bcef962df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil=CLMLIT&date=2023-02-05'\n",
    "#url = f'https://mesonet.agron.iastate.edu/api/1/nws/afos/list.json?cccc=KLZK&pil={station}&date={y}-{m:02}-{d:02}'\n",
    "\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "text = soup.get_text()\n",
    "\n",
    "#text.split('Skip to cccc:')[-1]\n",
    "\n",
    "text = f'[{text}]'\n",
    "json_item = json.loads(text)[0]\n",
    "\n",
    "# if not json_item['data']:\n",
    "#     print('no product issued')\n",
    "\n",
    "# elif json_item['data']:\n",
    "#     print(json_item['data']['text_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3916fde8-20f7-4954-8859-5cd9cdd9e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLIT'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_item['data'][0]['text_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b2c32e-884f-414e-bbd1-6b9b8297fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ = f'[{text}]'\n",
    "#print(text_)\n",
    "json1_data = json.loads(text_)[0]\n",
    "json1_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "452a5a5c-0abe-4e14-82ad-c1c25b58d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no product issued\n"
     ]
    }
   ],
   "source": [
    "if not json1_data['data']:\n",
    "    print('no product issued')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd230db-b7dd-4682-a08f-59d45373ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:56\n",
      "13:56\n",
      "13:56\n",
      "13:56\n"
     ]
    }
   ],
   "source": [
    "text = text.split('Skip to cccc:')[-1].split('College of Ag\\n')[0]\n",
    "\n",
    "\n",
    "# now lets iterate through the four PILs\n",
    "for station in ['LIT', 'LZK', 'HRO', 'PBF']:\n",
    "    if f'CLM{station}' in text:\n",
    "\n",
    "        product_time = text.split(f'CLM{station}')[-1].split('@')[-1].split('\\n')[0]\n",
    "        print(product_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db9d182-aef8-4204-b109-ef32057b3f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:54CLMLZK @11:54CLMPBF @11:54'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text.split('CLMLIT')[-1].split('x@')[-1].split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0917d359-76f1-4aef-98b5-676a225dfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the api page to parse the actual text\n",
    "\n",
    "#api_url = f'https://mesonet.agron.iastate.edu/api/1/nwstext/202302051153-KLZK-CXUS54-CLMLZK'\n",
    "api_url = f'https://mesonet.agron.iastate.edu/api/1/nwstext/202303041555-KLZK-CXUS54-CLMLIT'\n",
    "\n",
    "html = urlopen(api_url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a93868ef-04af-4e47-bf6b-6c7f845abf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mesonet.agron.iastate.edu/api/1/nwstext/202306060355-KLZK-CXUS54-CLMHRO\n",
      "104 \n",
      "CXUS54 KLZK 060357\n",
      "CLMHRO\n",
      "\n",
      "CLIMATE REPORT...UPDATED WITH SUPPLEMENTAL DATA \n",
      "NATIONAL WEATHER SERVICE LITTLE ROCK AR \n",
      "1055 PM CDT MON JUN 05 2023\n",
      "\n",
      "...................................\n",
      "\n",
      "...THE HARRISON CLIMATE SUMMARY FOR THE MONTH OF MAY 2023...\n",
      "\n",
      "CLIMATE NORMAL PERIOD 1991 TO 2020\n",
      "CLIMATE RECORD PERIOD 1891 TO 2023\n",
      "\n",
      "WEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \n",
      "                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \n",
      "                                          NORMAL                       \n",
      "................................................................\n",
      "TEMPERATURE (F)\n",
      "RECORD\n",
      " HIGH             99   05/29/1926                                      \n",
      "                       05/28/1926                                      \n",
      " LOW              26   05/02/1911                                      \n",
      "                       05/01/1903                                      \n",
      "HIGHEST           87   05/08         76      11       91  05/12        \n",
      "LOWEST            43   05/01         56     -13       45  05/04        \n",
      "AVG. MAXIMUM    78.2               76.6     1.6     76.7               \n",
      "AVG. MINIMUM    56.2               55.8     0.4     57.7               \n",
      "MEAN            67.2               66.2     1.0     67.2               \n",
      "DAYS MAX >= 90     0                0.7    -0.7        2               \n",
      "DAYS MAX <= 32     0                0.0     0.0        0               \n",
      "DAYS MIN <= 32     0                0.0     0.0        0               \n",
      "DAYS MIN <= 0      0                0.0     0.0        0               \n",
      "\n",
      "PRECIPITATION (INCHES)\n",
      "RECORD\n",
      " MAXIMUM       16.87   1961                                            \n",
      " MINIMUM        0.59   2012                                            \n",
      "TOTALS          5.21               4.81    0.40     6.64               \n",
      "DAILY AVG.      0.17               0.16    0.01     0.21               \n",
      "DAYS >= .01       13               11.8     1.2       13               \n",
      "DAYS >= .10        7                                   9               \n",
      "DAYS >= .50        4                                   3               \n",
      "DAYS >= 1.00       2                1.4     0.6        3               \n",
      "GREATEST\n",
      " 24 HR. TOTAL   2.31   05/10 TO 05/11                                  \n",
      " STORM TOTAL    1.44                                                   \n",
      " (MM/DD(HH))                                                           \n",
      "\n",
      "SNOWFALL (INCHES)\n",
      "RECORDS\n",
      " TOTAL           0.1   2013                                            \n",
      " 24 HR TOTAL     0.1   05/03/2013 TO 05/03/2013                        \n",
      " SNOW DEPTH        T   05/03/2013                                      \n",
      "TOTALS           0.0                0.0     0.0      0.0               \n",
      " LIQUID EQUIV   0.00               0.00    0.00     0.00               \n",
      "SINCE 7/1       15.1               11.5     3.6       MM               \n",
      " LIQUID 7/1     1.51               1.00    0.51       MM               \n",
      "SNOWDEPTH AVG.     0                                                   \n",
      "DAYS >= TRACE      0                 MM      MM        0               \n",
      "DAYS >= 1.0        0                                   0               \n",
      "GREATEST\n",
      " SNOW DEPTH        0                                                   \n",
      " 24 HR TOTAL     0.0    MM                           0.0               \n",
      "\n",
      "DEGREE DAYS\n",
      "HEATING TOTAL     51                 75     -24       80               \n",
      " SINCE 7/1      3546               3881    -335       MM               \n",
      "COOLING TOTAL    126                112      14      155               \n",
      " SINCE 1/1       150                152      -2       MM               \n",
      "\n",
      "FREEZE DATES\n",
      "RECORD\n",
      " EARLIEST     09/13/1902                                               \n",
      " LATEST       05/17/1912                                               \n",
      "EARLIEST                        10/18                                  \n",
      "LATEST                          04/14                                  \n",
      "................................................................\n",
      "\n",
      "WIND (MPH)\n",
      "AVERAGE WIND SPEED              5.5                                    \n",
      "HIGHEST WIND SPEED/DIRECTION    23/160    DATE  05/10                  \n",
      "HIGHEST GUST SPEED/DIRECTION    32/330    DATE  05/01                  \n",
      "\n",
      "SKY COVER\n",
      "POSSIBLE SUNSHINE (PERCENT)   MM                                       \n",
      "AVERAGE SKY COVER           0.33                                       \n",
      "NUMBER OF DAYS FAIR           18                                       \n",
      "NUMBER OF DAYS PC             11                                       \n",
      "NUMBER OF DAYS CLOUDY          2                                       \n",
      "\n",
      "\n",
      "WEATHER CONDITIONS. NUMBER OF DAYS WITH \n",
      "THUNDERSTORM              5     MIXED PRECIP               0          \n",
      "HEAVY RAIN                7     RAIN                       6           \n",
      "LIGHT RAIN               12     FREEZING RAIN              0          \n",
      "LT FREEZING RAIN          0     HAIL                       0         \n",
      "HEAVY SNOW                0     SLEET                      0         \n",
      "FOG                      13     FOG W/VIS <= 1/4 MILE      0          \n",
      "HAZE                      1                                            \n",
      "\n",
      "-  INDICATES NEGATIVE NUMBERS.\n",
      "R  INDICATES RECORD WAS SET OR TIED.\n",
      "MM INDICATES DATA IS MISSING.\n",
      "T  INDICATES TRACE AMOUNT.\n",
      "\n",
      "&&\n",
      "\n",
      ".MONTHLY AVERAGES...\n",
      "THE AVERAGE HIGH TEMPERATURE OF 78.2 (+1.6) WAS TIED FOR THE 55TH \n",
      "HOTTEST AND WARMEST SINCE 2018.\n",
      "\n",
      "THE AVERAGE LOW TEMPERATURE OF 56.2 (+0.4) WAS THE 37TH HOTTEST AND \n",
      "WARMEST SINCE 2022.\n",
      "\n",
      "THE AVERAGE TEMPERATURE OF 67.2 (+1.0) WAS TIED FOR THE 42TH HOTTEST \n",
      "AND WARMEST SINCE 2022.\n",
      "\n",
      "THE MONTHLY LOW TEMPERATURES WERE NEAR THE 30-YEAR CLIMATOLOGICAL \n",
      "AVERAGES. THE MONTHLY HIGH AND AVERAGE TEMPERATURES WERE SLIGHTLY \n",
      "ABOVE THE 30-YEAR CLIMATOLOGICAL AVERAGES.\n",
      "\n",
      ".DAILY TEMPERATURES... \n",
      "DAILY TEMPERATURES WERE AVERAGE ON 1 DAY.\n",
      "DAILY TEMPERATURES WERE ABOVE AVERAGE ON 16 DAYS.\n",
      "DAILY TEMPERATURES WERE BELOW AVERAGE ON 14 DAYS.\n",
      "\n",
      ".DAILY TEMPERATURE RECORDS TIED OR BROKEN DURING THE MONTH... \n",
      "NO DAILY TEMPERATURE RECORDS WERE TIED OR BROKEN.\n",
      "\n",
      ".MONTHLY RAINFALL... \n",
      "THE MONTHLY RAINFALL TOTAL OF 5.21 WAS TIED FOR THE 49TH WETTEST ON \n",
      "RECORD AND WETTEST SINCE 2022. THE MONTHLY RAINFALL WAS +0.40 ABOVE \n",
      "AVERAGE FOR THE MONTH.\n",
      "\n",
      ".DAILY RAINFALL RECORDS TIED OR BROKEN DURING THE MONTH... \n",
      "NO DAILY RAINFALL RECORDS WERE TIED OR BROKEN.\n",
      "\n",
      ".MONTHLY SNOWFALL... \n",
      "NO DAILY SNOWFALL WAS RECORDED.\n",
      "\n",
      ".DAILY SNOWFALL RECORDS TIED OR BROKEN DURING THE MONTH... \n",
      "NO DAILY SNOWFALL RECORDS WERE TIED OR BROKEN.\n",
      "\n",
      "$$\n",
      "\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "def text_parser(timestamp, pil):\n",
    "\n",
    "    y = timestamp.year\n",
    "    m = timestamp.month\n",
    "    d = timestamp.day\n",
    "    hh = timestamp.hour\n",
    "    mm = timestamp.minute\n",
    "    \n",
    "    api_url = f'https://mesonet.agron.iastate.edu/api/1/nwstext/{y}{m:02}{d:02}{hh:02}{mm:02}-KLZK-CXUS54-{pil}'\n",
    "    print(api_url)\n",
    "    \n",
    "    html = urlopen(api_url).read()\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    \n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "    \n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # parse out the highest and lowest temp data for the month from the text\n",
    "    high_temp_data = text.split('HIGHEST         ')[-1].split('LOWEST')[0].splitlines()   \n",
    "    low_temp_data = text.split('LOWEST           ')[-1].split('AVG. MAXIMUM')[0]  \n",
    "\n",
    "    get_maxmin_data(high_temp_data, low_temp_data, month)\n",
    "\n",
    "text_parser(timestamp, 'CLMHRO')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412b59a-3097-40a8-9e75-99c23b1be44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d475794-d0ef-4850-8e58-1ebbdd7b5f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "428406b6-7f75-4584-bf05-50a997080482",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2023\n",
    "m = 6\n",
    "d = 5\n",
    "hh = 22\n",
    "mm = 55\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "cb68efa7-c5eb-4a03-a309-e4dc99ebbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(y, m, d, hh, mm):\n",
    "\n",
    "    timestamp = datetime(y, m, d, hh, mm)\n",
    "    timestamp = timestamp.astimezone()\n",
    "    #return timestamp.astimezone(timezone.utc)\n",
    "\n",
    "\n",
    "timestamp = parse_timestamp(y, m, d, hh, mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "04b6f215-4c27-426b-aef5-a33f272c60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 \n",
      "CXUS54 KLZK 041555\n",
      "CLMLIT\n",
      "\n",
      "CLIMATE REPORT \n",
      "NATIONAL WEATHER SERVICE LITTLE ROCK AR\n",
      "955 AM CST SAT MAR 04 2023\n",
      "\n",
      "...................................\n",
      "\n",
      "...THE LITTLE ROCK ADAMS FIELD CLIMATE SUMMARY FOR THE MONTH OF FEBRUARY 2023...\n",
      "\n",
      "CLIMATE NORMAL PERIOD 1991 TO 2020\n",
      "CLIMATE RECORD PERIOD 1874 TO 2023\n",
      "\n",
      "WEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \n",
      "                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \n",
      "                                          NORMAL                       \n",
      "................................................................\n",
      "TEMPERATURE (F)\n",
      "RECORD\n",
      " HIGH             87   02/25/1918                                      \n",
      " LOW             -12   02/12/1899                                      \n",
      "HIGHEST           81   02/28         56      25       72  02/11        \n",
      "                                                          02/17        \n",
      "LOWEST            27   02/18         35      -8       23  02/05        \n",
      "                       02/04                                           \n",
      "                                                          02/06        \n",
      "                                                          02/13        \n",
      "AVG. MAXIMUM    62.1               55.2     6.9     57.0               \n",
      "AVG. MINIMUM    41.7               34.2     7.5     32.5               \n",
      "MEAN            51.9               44.7     7.2     44.8               \n",
      "DAYS MAX >= 90     0                0.0     0.0        0               \n",
      "DAYS MAX <= 32     1                0.7     0.3        1               \n",
      "DAYS MIN <= 32     5               10.9    -5.9       17               \n",
      "DAYS MIN <= 0      0                0.0     0.0        0               \n",
      "\n",
      "PRECIPITATION (INCHES)\n",
      "RECORD\n",
      " MAXIMUM       14.04   2018                                            \n",
      " MINIMUM        0.51   1947                                            \n",
      "TOTALS          7.62               3.97    3.65     5.29               \n",
      "DAILY AVG.      0.27               0.14    0.13     0.19               \n",
      "DAYS >= .01       10                9.3     0.7        6               \n",
      "DAYS >= .10        8                                   3               \n",
      "DAYS >= .50        3                                   0               \n",
      "DAYS >= 1.00       2                1.2     0.8        0               \n",
      "GREATEST\n",
      " 24 HR. TOTAL   4.19   02/24 TO 02/24                                  \n",
      " STORM TOTAL    4.19                                                   \n",
      " (MM/DD(HH))                                                           \n",
      "\n",
      "SNOWFALL (INCHES)\n",
      "RECORDS\n",
      " TOTAL          20.3   2021                                            \n",
      " 24 HR TOTAL    11.8   02/17/2021 TO 02/17/2021                        \n",
      " SNOW DEPTH       15   02/18/2021                                      \n",
      "TOTALS             T                1.6    -1.6      2.1               \n",
      " LIQUID EQUIV      T               0.10   -0.10     0.21               \n",
      "SINCE 7/1        0.1                3.3    -3.2       MM               \n",
      " LIQUID 7/1     0.01               0.30   -0.29       MM               \n",
      "SNOWDEPTH AVG.     T                                                   \n",
      "DAYS >= TRACE      1                0.9     0.1        6               \n",
      "DAYS >= 1.0        0                                   1               \n",
      "GREATEST\n",
      " SNOW DEPTH       MM                                                   \n",
      " 24 HR TOTAL       T                                  MM               \n",
      "\n",
      "DEGREE DAYS\n",
      "HEATING TOTAL    367                569    -202      561               \n",
      " SINCE 7/1      1960               2589    -629       MM               \n",
      "COOLING TOTAL      7                  1       6        0               \n",
      " SINCE 1/1        14                  1      13       MM               \n",
      "\n",
      "FREEZE DATES\n",
      "RECORD\n",
      " EARLIEST     10/20/1989                                               \n",
      " LATEST       04/19/1983                                               \n",
      "EARLIEST                        11/12                                  \n",
      "LATEST                          03/13                                  \n",
      "................................................................\n",
      "\n",
      "WIND (MPH)\n",
      "AVERAGE WIND SPEED              8.2                                    \n",
      "HIGHEST WIND SPEED/DIRECTION    36/300    DATE  02/22                  \n",
      "HIGHEST GUST SPEED/DIRECTION    46/300    DATE  02/22                  \n",
      "\n",
      "SKY COVER\n",
      "POSSIBLE SUNSHINE (PERCENT)   MM                                       \n",
      "AVERAGE SKY COVER           0.65                                       \n",
      "NUMBER OF DAYS FAIR            6                                       \n",
      "NUMBER OF DAYS PC              7                                       \n",
      "NUMBER OF DAYS CLOUDY         15                                       \n",
      "\n",
      "\n",
      "WEATHER CONDITIONS. NUMBER OF DAYS WITH \n",
      "THUNDERSTORM              3     MIXED PRECIP               0          \n",
      "HEAVY RAIN                4     RAIN                       6           \n",
      "LIGHT RAIN               12     FREEZING RAIN              1           \n",
      "LT FREEZING RAIN          2     HAIL                       0          \n",
      "HEAVY SNOW                0     SLEET                      0         \n",
      "FOG                      12     FOG W/VIS <= 1/4 MILE      3           \n",
      "HAZE                      6                                            \n",
      "\n",
      "-  INDICATES NEGATIVE NUMBERS.\n",
      "R  INDICATES RECORD WAS SET OR TIED.\n",
      "MM INDICATES DATA IS MISSING.\n",
      "T  INDICATES TRACE AMOUNT.\n",
      "\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "# text_r = text.splitlines()\n",
    "\n",
    "# for line in text_r:\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f00e442a-c33b-40fc-aac0-945d6673b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['234 ',\n",
       " 'CXUS54 KLZK 041555',\n",
       " 'CLMLIT',\n",
       " '',\n",
       " 'CLIMATE REPORT ',\n",
       " 'NATIONAL WEATHER SERVICE LITTLE ROCK AR',\n",
       " '955 AM CST SAT MAR 04 2023',\n",
       " '',\n",
       " '...................................',\n",
       " '',\n",
       " '...THE LITTLE ROCK ADAMS FIELD CLIMATE SUMMARY FOR THE MONTH OF FEBRUARY 2023...',\n",
       " '',\n",
       " 'CLIMATE NORMAL PERIOD 1991 TO 2020',\n",
       " 'CLIMATE RECORD PERIOD 1874 TO 2023',\n",
       " '',\n",
       " \"WEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \",\n",
       " '                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       ',\n",
       " '                                          NORMAL                       ',\n",
       " '................................................................',\n",
       " 'TEMPERATURE (F)',\n",
       " 'RECORD',\n",
       " ' HIGH             87   02/25/1918                                      ',\n",
       " ' LOW             -12   02/12/1899                                      ',\n",
       " 'HIGHEST           81   02/28         56      25       72  02/11        ',\n",
       " '                                                          02/17        ',\n",
       " 'LOWEST            27   02/18         35      -8       23  02/05        ',\n",
       " '                       02/04                                           ',\n",
       " '                                                          02/06        ',\n",
       " '                                                          02/13        ',\n",
       " 'AVG. MAXIMUM    62.1               55.2     6.9     57.0               ',\n",
       " 'AVG. MINIMUM    41.7               34.2     7.5     32.5               ',\n",
       " 'MEAN            51.9               44.7     7.2     44.8               ',\n",
       " 'DAYS MAX >= 90     0                0.0     0.0        0               ',\n",
       " 'DAYS MAX <= 32     1                0.7     0.3        1               ',\n",
       " 'DAYS MIN <= 32     5               10.9    -5.9       17               ',\n",
       " 'DAYS MIN <= 0      0                0.0     0.0        0               ',\n",
       " '',\n",
       " 'PRECIPITATION (INCHES)',\n",
       " 'RECORD',\n",
       " ' MAXIMUM       14.04   2018                                            ',\n",
       " ' MINIMUM        0.51   1947                                            ',\n",
       " 'TOTALS          7.62               3.97    3.65     5.29               ',\n",
       " 'DAILY AVG.      0.27               0.14    0.13     0.19               ',\n",
       " 'DAYS >= .01       10                9.3     0.7        6               ',\n",
       " 'DAYS >= .10        8                                   3               ',\n",
       " 'DAYS >= .50        3                                   0               ',\n",
       " 'DAYS >= 1.00       2                1.2     0.8        0               ',\n",
       " 'GREATEST',\n",
       " ' 24 HR. TOTAL   4.19   02/24 TO 02/24                                  ',\n",
       " ' STORM TOTAL    4.19                                                   ',\n",
       " ' (MM/DD(HH))                                                           ',\n",
       " '',\n",
       " 'SNOWFALL (INCHES)',\n",
       " 'RECORDS',\n",
       " ' TOTAL          20.3   2021                                            ',\n",
       " ' 24 HR TOTAL    11.8   02/17/2021 TO 02/17/2021                        ',\n",
       " ' SNOW DEPTH       15   02/18/2021                                      ',\n",
       " 'TOTALS             T                1.6    -1.6      2.1               ',\n",
       " ' LIQUID EQUIV      T               0.10   -0.10     0.21               ',\n",
       " 'SINCE 7/1        0.1                3.3    -3.2       MM               ',\n",
       " ' LIQUID 7/1     0.01               0.30   -0.29       MM               ',\n",
       " 'SNOWDEPTH AVG.     T                                                   ',\n",
       " 'DAYS >= TRACE      1                0.9     0.1        6               ',\n",
       " 'DAYS >= 1.0        0                                   1               ',\n",
       " 'GREATEST',\n",
       " ' SNOW DEPTH       MM                                                   ',\n",
       " ' 24 HR TOTAL       T                                  MM               ',\n",
       " '',\n",
       " 'DEGREE DAYS',\n",
       " 'HEATING TOTAL    367                569    -202      561               ',\n",
       " ' SINCE 7/1      1960               2589    -629       MM               ',\n",
       " 'COOLING TOTAL      7                  1       6        0               ',\n",
       " ' SINCE 1/1        14                  1      13       MM               ',\n",
       " '',\n",
       " 'FREEZE DATES',\n",
       " 'RECORD',\n",
       " ' EARLIEST     10/20/1989                                               ',\n",
       " ' LATEST       04/19/1983                                               ',\n",
       " 'EARLIEST                        11/12                                  ',\n",
       " 'LATEST                          03/13                                  ',\n",
       " '................................................................',\n",
       " '',\n",
       " 'WIND (MPH)',\n",
       " 'AVERAGE WIND SPEED              8.2                                    ',\n",
       " 'HIGHEST WIND SPEED/DIRECTION    36/300    DATE  02/22                  ',\n",
       " 'HIGHEST GUST SPEED/DIRECTION    46/300    DATE  02/22                  ',\n",
       " '',\n",
       " 'SKY COVER',\n",
       " 'POSSIBLE SUNSHINE (PERCENT)   MM                                       ',\n",
       " 'AVERAGE SKY COVER           0.65                                       ',\n",
       " 'NUMBER OF DAYS FAIR            6                                       ',\n",
       " 'NUMBER OF DAYS PC              7                                       ',\n",
       " 'NUMBER OF DAYS CLOUDY         15                                       ',\n",
       " '',\n",
       " '',\n",
       " 'WEATHER CONDITIONS. NUMBER OF DAYS WITH ',\n",
       " 'THUNDERSTORM              3     MIXED PRECIP               0          ',\n",
       " 'HEAVY RAIN                4     RAIN                       6           ',\n",
       " 'LIGHT RAIN               12     FREEZING RAIN              1           ',\n",
       " 'LT FREEZING RAIN          2     HAIL                       0          ',\n",
       " 'HEAVY SNOW                0     SLEET                      0         ',\n",
       " 'FOG                      12     FOG W/VIS <= 1/4 MILE      3           ',\n",
       " 'HAZE                      6                                            ',\n",
       " '',\n",
       " '-  INDICATES NEGATIVE NUMBERS.',\n",
       " 'R  INDICATES RECORD WAS SET OR TIED.',\n",
       " 'MM INDICATES DATA IS MISSING.',\n",
       " 'T  INDICATES TRACE AMOUNT.',\n",
       " '',\n",
       " '$$']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc06c6-21d8-402f-93d3-9b84a3722037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4e76a-fd7f-49a6-b75f-4d3aae4e4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxmin_data(high_data, low_data):\n",
    "\n",
    "    '''\n",
    "    Worker function to extract high and low data/dates from the CLM products.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # filter out the '' values inside the lists\n",
    "    high_data = list(filter(None, high_data))\n",
    "    low_data = list(filter(None, low_data))\n",
    "\n",
    "    print('high data')\n",
    "    print(high_data)\n",
    "    print('low data')\n",
    "    print(low_data)\n",
    "    print('\\n')\n",
    "\n",
    "    # now lets get some data\n",
    "    data_dict['highs'].append(high_data[0])\n",
    "    data_dict['lows'].append(low_data[0])\n",
    "\n",
    "    data_dict['high_dates'].append([high_data[1]])\n",
    "    data_dict['low_dates'].append([low_data[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7c4be3c6-1e08-4de5-8a7f-ade633f19969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIT': {'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'FEB': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}},\n",
       " 'LZK': {'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'FEB': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}},\n",
       " 'PBF': {'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'FEB': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}},\n",
       " 'HRO': {'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'FEB': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       "  'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}}}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish our main working dictionary\n",
    "data_dict = {}\n",
    "\n",
    "for s in ['LIT', 'LZK', 'PBF', 'HRO']:\n",
    "    _data_dict = {\n",
    "        f'{s}' : {}\n",
    "    }\n",
    "    data_dict.update(_data_dict)\n",
    "\n",
    "# now add the months\n",
    "for key in data_dict:\n",
    "    for i in range(1,13):\n",
    "        _data_dict = {\n",
    "             f'{calendar.month_name[i][:3].upper()}' : {# generate the abbreviated month names\n",
    "            'highs': [],\n",
    "            'high_dates': [], # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "            'lows': [],\n",
    "            'low_dates': []  # these should still contain 12 items, but will be lists inside lists in case of multiple dates                                     }\n",
    "                }\n",
    "            }\n",
    "        data_dict[key].update(_data_dict)\n",
    "\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "98ef3c7a-4c28-41ff-abe9-d3a5d48242a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'highs': [], 'lows': []}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = {\n",
    "    'LIT' : {\n",
    "        'JAN' : {\n",
    "            'highs' : [],\n",
    "            'lows' : []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "test_dict['LIT']['JAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5d535a65-02d6-47e9-819b-ff53d4054dc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LIT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLIT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJAN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m test_dict\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LIT'"
     ]
    }
   ],
   "source": [
    "test_dict['LIT']['JAN'] = []\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cec49d32-5635-4456-b022-83d04ddd9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27   02/18         35      -8       23  02/05        \n",
      "                       02/04                                           \n",
      "                                                          02/06        \n",
      "                                                          02/13        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parse out the highest and lowest temp data for the month from the text\n",
    "high_temp_data = text.split('HIGHEST         ')[-1].split('LOWEST')[0].splitlines()   \n",
    "low_temp_data = text.split('LOWEST           ')[-1].split('AVG. MAXIMUM')[0]      \n",
    "\n",
    "print(low_temp_data)\n",
    "# multiple lines would indicate multiple dates of occurrence of the lowest temp\n",
    "# if len(low_temp_data) > 1:\n",
    "\n",
    "#     # first get temp and first date of occurrence\n",
    "#     print(low_temp_data[0].split(' '))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4c834d50-2e74-4f53-bd8f-b7717f0b09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27', '02/18', '35', '-8', '23', '02/05', '\\n', '02/04', '\\n', '02/06', '\\n', '02/13', '\\n']\n"
     ]
    }
   ],
   "source": [
    "_low_temp_data = list(filter(None, low_temp_data.split(' ')))\n",
    "\n",
    "print(_low_temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "89de9c4c-21f9-4690-843a-dc9473dd55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_maxmin_data(high_data, low_data, month):\n",
    "\n",
    "    '''\n",
    "    Worker function to extract high and low data/dates from the CLM products.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # first filter the line of temp data\n",
    "    filtered_low_temp_data = list(filter(None, low_temp_data.split(' '))) # low temp data\n",
    "    filtered_high_temp_data = list(filter(None, high_temp_data.split(' '))) # high temp data\n",
    "    \n",
    "    # lets add the high and low values to the dictionary\n",
    "    data_dict[month]['lows'].append(filtered_low_temp_data[0])\n",
    "    data_dict[month]['highs'].append(filtered_high_temp_data[0])\n",
    "\n",
    "    \n",
    "    ## LOW TEMP DATA DATES ##\n",
    "    #---------------------------------------------------------------\n",
    "    # check how many lines exist in the list\n",
    "    # if only one line, then just one date to grab\n",
    "    if len(low_temp_data.splitlines()) == 1:\n",
    "    \n",
    "        data_dict[month]['low_dates'].append([filtered_low_temp_data[1]])\n",
    "    \n",
    "    # if there are multiple rows of low temp data, then multiple dates to grab\n",
    "    elif len(low_temp_data.splitlines()) > 1:\n",
    "        dates = []\n",
    "        \n",
    "        # grab the first date in the line\n",
    "        dates.append(filtered_low_temp_data[1])\n",
    "    \n",
    "        # now iterate and find the rest of the dates\n",
    "        for line in low_temp_data.splitlines()[1:]:\n",
    "            if count_spaces(line):\n",
    "                dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "    \n",
    "        data_dict[month]['low_dates'].append(dates)\n",
    "    \n",
    "    \n",
    "    ## HIGH TEMP DATA DATES ##\n",
    "    #---------------------------------------------------------------\n",
    "    # check how many lines exist in the list\n",
    "    # if only one line, then just one date to grab\n",
    "    if len(high_temp_data.splitlines()) == 1:\n",
    "    \n",
    "        data_dict[month]['high_dates'].append([filtered_high_temp_data[1]])\n",
    "    \n",
    "    # if there are multiple rows of high temp data, then multiple dates to grab\n",
    "    elif len(high_temp_data.splitlines()) > 1:\n",
    "        dates = []\n",
    "        \n",
    "        # grab the first date in the line\n",
    "        dates.append(filtered_high_temp_data[1])\n",
    "    \n",
    "        # now iterate and find the rest of the dates\n",
    "        for line in high_temp_data.splitlines()[1:]:\n",
    "            if count_spaces(line):\n",
    "                dates.append(list(filter(None, (line.split(' '))))[0])\n",
    "    \n",
    "        data_dict[month]['high_dates'].append(dates)\n",
    "\n",
    "    \n",
    "#data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5352eb1c-ff59-45e4-bf64-6f25b17e814d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'FEB': {'highs': [],\n",
       "  'high_dates': [],\n",
       "  'lows': [' 27   02/18         35      -8       23  02/05        ',\n",
       "   ' 27   02/18         35      -8       23  02/05        ',\n",
       "   '',\n",
       "   '',\n",
       "   ''],\n",
       "  'low_dates': []},\n",
       " 'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2c1d1217-af82-43a1-8842-3f6eee2cee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = '                       02/04                                           '\n",
    "\n",
    "test_string.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2cff0a50-a578-4ae0-a0fa-635dfac70019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/04'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date = list(filter(None, (test_string.split(' '))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ae19c7ee-e5af-489b-8e12-ff026172f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "def count_spaces(line):\n",
    "\n",
    "    # this should be the date in the line\n",
    "    split_date = list(filter(None, (line.split(' '))))[0]\n",
    "\n",
    "    # this is the number of spaces for it to be a date occurred that month\n",
    "    if line.split(split_date)[0].count(' ') == 23:\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# if count_spaces(test_string):\n",
    "#     print('true')\n",
    "# else:\n",
    "#     print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35aa586a-421e-4d9a-866c-6bd16ef52633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're just importing datafiles, but first lets import from the api url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48d0b-587b-45f7-becd-558e1f92b181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b847ed-c1a6-40a7-a6eb-97d84a53ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 \n",
      "CXUS54 KLZK 151933\n",
      "CLMLIT\n",
      "\n",
      "CLIMATE REPORT...UPDATED WITH SUPPLEMENTAL DATA \n",
      "NATIONAL WEATHER SERVICE LITTLE ROCK AR\n",
      "0135 PM CST MON JAN 15 2024\n",
      "\n",
      "...................................\n",
      "\n",
      "...THE LITTLE ROCK ADAMS FIELD CLIMATE SUMMARY FOR THE MONTH OF DECEMBER 2023...\n",
      "\n",
      "CLIMATE NORMAL PERIOD 1991 TO 2020\n",
      "CLIMATE RECORD PERIOD 1874 TO 2023\n",
      "\n",
      "WEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \n",
      "                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \n",
      "                                          NORMAL                       \n",
      "................................................................\n",
      "TEMPERATURE (F)\n",
      "RECORD\n",
      " HIGH             81   12/26/2015                                      \n",
      " LOW              -1   12/23/1989                                      \n",
      "                       12/24/1963                                      \n",
      "HIGHEST           69   12/01         53      16       74  12/29        \n",
      "LOWEST            29   12/19         34      -5        2  12/23        \n",
      "AVG. MAXIMUM    59.8               52.6     7.2     53.9               \n",
      "AVG. MINIMUM    37.9               33.3     4.6     36.5               \n",
      "MEAN            48.8               43.0     5.8     45.2               \n",
      "DAYS MAX >= 90     0                0.0     0.0        0               \n",
      "DAYS MAX <= 32     0                0.9    -0.9        1               \n",
      "DAYS MIN <= 32     7               13.4    -6.4       12               \n",
      "DAYS MIN <= 0      0                0.0     0.0        0               \n",
      "\n",
      "PRECIPITATION (INCHES)\n",
      "RECORD\n",
      " MAXIMUM       16.92   1884                                            \n",
      " MINIMUM        0.14   1889                                            \n",
      "TOTALS          1.40               5.08   -3.68     6.15               \n",
      "DAILY AVG.      0.05               0.16   -0.11     0.20               \n",
      "DAYS >= .01        5                9.5    -4.5       13               \n",
      "DAYS >= .10        3                                   8               \n",
      "DAYS >= .50        1                                   4               \n",
      "DAYS >= 1.00       0                1.5    -1.5        2               \n",
      "GREATEST\n",
      " 24 HR. TOTAL   2.21   11/30 TO 12/01                                  \n",
      " STORM TOTAL    0.79                                                   \n",
      " (MM/DD(HH))                                                           \n",
      "\n",
      "SNOWFALL (INCHES)\n",
      "RECORDS\n",
      " TOTAL          10.3   2012                                            \n",
      " 24 HR TOTAL    10.3   12/25/2012 TO 12/26/2012                        \n",
      " SNOW DEPTH       10   12/26/2012                                      \n",
      "TOTALS           0.0                0.6    -0.6      0.1               \n",
      " LIQUID EQUIV   0.00               0.02   -0.02     0.00               \n",
      "SINCE 7/1        0.0                0.6    -0.6       MM               \n",
      " LIQUID 7/1     0.00               0.00    0.00       MM               \n",
      "SNOWDEPTH AVG.     0                                                   \n",
      "DAYS >= TRACE      0                0.3    -0.3        2               \n",
      "DAYS >= 1.0        0                                   0               \n",
      "GREATEST\n",
      " SNOW DEPTH        0                                                   \n",
      " 24 HR TOTAL      MM                                  MM               \n",
      "\n",
      "DEGREE DAYS\n",
      "HEATING TOTAL    496                684    -188      611               \n",
      " SINCE 7/1       886               1264    -378       MM               \n",
      "COOLING TOTAL      0                  1      -1        3               \n",
      " SINCE 1/1      2695               1990     705       MM               \n",
      "\n",
      "FREEZE DATES\n",
      "RECORD\n",
      " EARLIEST     10/20/1989                                               \n",
      " LATEST       04/19/1983                                               \n",
      "EARLIEST                        11/01                                  \n",
      "LATEST                          03/20                                  \n",
      "................................................................\n",
      "\n",
      "WIND (MPH)\n",
      "AVERAGE WIND SPEED              6.5                                    \n",
      "HIGHEST WIND SPEED/DIRECTION    25/020    DATE  12/09                  \n",
      "HIGHEST GUST SPEED/DIRECTION    36/010    DATE  12/09                  \n",
      "\n",
      "SKY COVER\n",
      "POSSIBLE SUNSHINE (PERCENT)   MM                                       \n",
      "AVERAGE SKY COVER           0.48                                       \n",
      "NUMBER OF DAYS FAIR           11                                       \n",
      "NUMBER OF DAYS PC             10                                       \n",
      "NUMBER OF DAYS CLOUDY         10                                       \n",
      "\n",
      "\n",
      "WEATHER CONDITIONS. NUMBER OF DAYS WITH \n",
      "THUNDERSTORM              1     MIXED PRECIP               0          \n",
      "HEAVY RAIN                1     RAIN                       4           \n",
      "LIGHT RAIN                9     FREEZING RAIN              0          \n",
      "LT FREEZING RAIN          0     HAIL                       0         \n",
      "HEAVY SNOW                0     SLEET                      0         \n",
      "FOG                       9     FOG W/VIS <= 1/4 MILE      2           \n",
      "HAZE                      3                                            \n",
      "\n",
      "-  INDICATES NEGATIVE NUMBERS.\n",
      "R  INDICATES RECORD WAS SET OR TIED.\n",
      "MM INDICATES DATA IS MISSING.\n",
      "T  INDICATES TRACE AMOUNT.\n",
      "\n",
      "&&\n",
      "\n",
      "﻿...ADDITIONAL DATA FOR LITTLE ROCK ADAMS FIELD – DECEMBER 2023...\n",
      "\n",
      ".MONTHLY AVERAGE... \n",
      "THE AVERAGE HIGH TEMPERATURE OF 59.8 (+7.2) WAS THE 5TH HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE AVERAGE LOW TEMPERATURE OF 37.9 (+4.6) WAS THE 33RD HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE AVERAGE MEAN TEMPERATURE OF 48.8 (+5.8) WAS THE 15TH HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE MONTHLY HIGH, LOW, AND MONTH AVERAGE TEMPERATURES WERE WELL \n",
      "ABOVE THE 30-YEAR CLIMATOLOGICAL AVERAGES BY AN AMOUNT OF 4 TO 7 \n",
      "DEGREES.\n",
      " \n",
      ".DAILY TEMPERATURES...\n",
      "DAILY TEMPERATURES WERE AVERAGE FOR 1 DAY.\n",
      "DAILY TEMPERATURES WERE ABOVE AVERAGE ON 27 DAYS.\n",
      "DAILY TEMPERATURES WERE BELOW AVERAGE ON 3 DAYS.\n",
      " \n",
      ".DAILY TEMPERATURE RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY TEMPERATURE RECORDS WERE TIED OR BROKEN. \n",
      "\n",
      ".MONTHLY RAINFALL...\n",
      "THE MONTHLY RAINFALL TOTAL OF 1.40 WAS TIED FOR THE 11TH DRIEST ON \n",
      "RECORD AND DRIEST SINCE 2005.THE MONTHLY RAINFALL WAS -3.68 BELOW \n",
      "AVERAGE FOR THE MONTH.\n",
      " \n",
      ".DAILY RAINFALL RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY RAINFALL RECORDS WERE TIED OR BROKEN. \n",
      "\n",
      ".MONTHLY SNOWFALL...\n",
      "NO MONTHLY SNOWFALL WAS RECORDED.\n",
      "THE MONTHLY SNOWFALL WAS -0.6 BELOW AVERAGE FOR THE MONTH.\n",
      " \n",
      ".DAILY SNOWFALL RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY SNOWFALL RECORDS WERE TIED OR BROKEN.\n",
      "\n",
      ".ADDITIONAL SIGNIFICANT EVENTS DURING THE MONTH...\n",
      "NO ADDITIONAL SIGNIFICANT EVENTS OCCURRED DURING THE MONTH.\n",
      "\n",
      "$$\n",
      "\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "# this is the api url, it just displays the data in raw text\n",
    "\n",
    "url = 'https://mesonet.agron.iastate.edu/api/1/nwstext/202401151935-KLZK-CXUS54-CLMLIT'\n",
    "\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "#print(text)\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da0a9202-ea13-4eda-a02c-f5c038b73bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"447 \\nCXUS54 KLZK 151933\\nCLMLIT\\n\\nCLIMATE REPORT...UPDATED WITH SUPPLEMENTAL DATA \\nNATIONAL WEATHER SERVICE LITTLE ROCK AR\\n0135 PM CST MON JAN 15 2024\\n\\n...................................\\n\\n...THE LITTLE ROCK ADAMS FIELD CLIMATE SUMMARY FOR THE MONTH OF DECEMBER 2023...\\n\\nCLIMATE NORMAL PERIOD 1991 TO 2020\\nCLIMATE RECORD PERIOD 1874 TO 2023\\n\\nWEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \\n                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \\n                                          NORMAL                       \\n................................................................\\nTEMPERATURE (F)\\nRECORD\\n HIGH             81   12/26/2015                                      \\n LOW              -1   12/23/1989                                      \\n                       12/24/1963                                      \\nHIGHEST           69   12/01         53      16       74  12/29        \\nLOWEST            29   12/19         34      -5        2  12/23        \\nAVG. MAXIMUM    59.8               52.6     7.2     53.9               \\nAVG. MINIMUM    37.9               33.3     4.6     36.5               \\nMEAN            48.8               43.0     5.8     45.2               \\nDAYS MAX >= 90     0                0.0     0.0        0               \\nDAYS MAX <= 32     0                0.9    -0.9        1               \\nDAYS MIN <= 32     7               13.4    -6.4       12               \\nDAYS MIN <= 0      0                0.0     0.0        0               \\n\\nPRECIPITATION (INCHES)\\nRECORD\\n MAXIMUM       16.92   1884                                            \\n MINIMUM        0.14   1889                                            \\nTOTALS          1.40               5.08   -3.68     6.15               \\nDAILY AVG.      0.05               0.16   -0.11     0.20               \\nDAYS >= .01        5                9.5    -4.5       13               \\nDAYS >= .10        3                                   8               \\nDAYS >= .50        1                                   4               \\nDAYS >= 1.00       0                1.5    -1.5        2               \\nGREATEST\\n 24 HR. TOTAL   2.21   11/30 TO 12/01                                  \\n STORM TOTAL    0.79                                                   \\n (MM/DD(HH))                                                           \\n\\nSNOWFALL (INCHES)\\nRECORDS\\n TOTAL          10.3   2012                                            \\n 24 HR TOTAL    10.3   12/25/2012 TO 12/26/2012                        \\n SNOW DEPTH       10   12/26/2012                                      \\nTOTALS           0.0                0.6    -0.6      0.1               \\n LIQUID EQUIV   0.00               0.02   -0.02     0.00               \\nSINCE 7/1        0.0                0.6    -0.6       MM               \\n LIQUID 7/1     0.00               0.00    0.00       MM               \\nSNOWDEPTH AVG.     0                                                   \\nDAYS >= TRACE      0                0.3    -0.3        2               \\nDAYS >= 1.0        0                                   0               \\nGREATEST\\n SNOW DEPTH        0                                                   \\n 24 HR TOTAL      MM                                  MM               \\n\\nDEGREE DAYS\\nHEATING TOTAL    496                684    -188      611               \\n SINCE 7/1       886               1264    -378       MM               \\nCOOLING TOTAL      0                  1      -1        3               \\n SINCE 1/1      2695               1990     705       MM               \\n\\nFREEZE DATES\\nRECORD\\n EARLIEST     10/20/1989                                               \\n LATEST       04/19/1983                                               \\nEARLIEST                        11/01                                  \\nLATEST                          03/20                                  \\n................................................................\\n\\nWIND (MPH)\\nAVERAGE WIND SPEED              6.5                                    \\nHIGHEST WIND SPEED/DIRECTION    25/020    DATE  12/09                  \\nHIGHEST GUST SPEED/DIRECTION    36/010    DATE  12/09                  \\n\\nSKY COVER\\nPOSSIBLE SUNSHINE (PERCENT)   MM                                       \\nAVERAGE SKY COVER           0.48                                       \\nNUMBER OF DAYS FAIR           11                                       \\nNUMBER OF DAYS PC             10                                       \\nNUMBER OF DAYS CLOUDY         10                                       \\n\\n\\nWEATHER CONDITIONS. NUMBER OF DAYS WITH \\nTHUNDERSTORM              1     MIXED PRECIP               0          \\nHEAVY RAIN                1     RAIN                       4           \\nLIGHT RAIN                9     FREEZING RAIN              0          \\nLT FREEZING RAIN          0     HAIL                       0         \\nHEAVY SNOW                0     SLEET                      0         \\nFOG                       9     FOG W/VIS <= 1/4 MILE      2           \\nHAZE                      3                                            \\n\\n-  INDICATES NEGATIVE NUMBERS.\\nR  INDICATES RECORD WAS SET OR TIED.\\nMM INDICATES DATA IS MISSING.\\nT  INDICATES TRACE AMOUNT.\\n\\n&&\\n\\n\\ufeff...ADDITIONAL DATA FOR LITTLE ROCK ADAMS FIELD – DECEMBER 2023...\\n\\n.MONTHLY AVERAGE... \\nTHE AVERAGE HIGH TEMPERATURE OF 59.8 (+7.2) WAS THE 5TH HOTTEST AND \\nWARMEST SINCE 2021.\\n\\nTHE AVERAGE LOW TEMPERATURE OF 37.9 (+4.6) WAS THE 33RD HOTTEST AND \\nWARMEST SINCE 2021.\\n\\nTHE AVERAGE MEAN TEMPERATURE OF 48.8 (+5.8) WAS THE 15TH HOTTEST AND \\nWARMEST SINCE 2021.\\n\\nTHE MONTHLY HIGH, LOW, AND MONTH AVERAGE TEMPERATURES WERE WELL \\nABOVE THE 30-YEAR CLIMATOLOGICAL AVERAGES BY AN AMOUNT OF 4 TO 7 \\nDEGREES.\\n \\n.DAILY TEMPERATURES...\\nDAILY TEMPERATURES WERE AVERAGE FOR 1 DAY.\\nDAILY TEMPERATURES WERE ABOVE AVERAGE ON 27 DAYS.\\nDAILY TEMPERATURES WERE BELOW AVERAGE ON 3 DAYS.\\n \\n.DAILY TEMPERATURE RECORDS TIED OR BROKEN DURING THE MONTH...\\nNO DAILY TEMPERATURE RECORDS WERE TIED OR BROKEN. \\n\\n.MONTHLY RAINFALL...\\nTHE MONTHLY RAINFALL TOTAL OF 1.40 WAS TIED FOR THE 11TH DRIEST ON \\nRECORD AND DRIEST SINCE 2005.THE MONTHLY RAINFALL WAS -3.68 BELOW \\nAVERAGE FOR THE MONTH.\\n \\n.DAILY RAINFALL RECORDS TIED OR BROKEN DURING THE MONTH...\\nNO DAILY RAINFALL RECORDS WERE TIED OR BROKEN. \\n\\n.MONTHLY SNOWFALL...\\nNO MONTHLY SNOWFALL WAS RECORDED.\\nTHE MONTHLY SNOWFALL WAS -0.6 BELOW AVERAGE FOR THE MONTH.\\n \\n.DAILY SNOWFALL RECORDS TIED OR BROKEN DURING THE MONTH...\\nNO DAILY SNOWFALL RECORDS WERE TIED OR BROKEN.\\n\\n.ADDITIONAL SIGNIFICANT EVENTS DURING THE MONTH...\\nNO ADDITIONAL SIGNIFICANT EVENTS OCCURRED DURING THE MONTH.\\n\\n$$\\n\\n70\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e29e6e22-84fb-49e4-94af-44b8c717f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7dc5f8bb-d06f-4b88-8d38-dc00ab930f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RECORD\\n HIGH             81   12/26/2015                                      \\n LOW              -1   12/23/1989                                      \\n                       12/24/1963                                      \\nHIGHEST           69   12/01         53      16       74  12/29        \\nLOWEST            29   12/19         34      -5        2  12/23        \\nAVG. MAXIMUM    59.8               52.6     7.2     53.9               \\nAVG. MINIMUM    37.9               33.3     4.6     36.5               \\nMEAN            48.8               43.0     5.8     45.2               \\nDAYS MAX >= 90     0                0.0     0.0        0               \\nDAYS MAX <= 32     0                0.9    -0.9        1               \\nDAYS MIN <= 32     7               13.4    -6.4       12               \\nDAYS MIN <= 0      0                0.0     0.0        0               \\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = text.split('\\n................................................................\\nTEMPERATURE (F)\\n')[-1].split('\\nPRECIPITATION (INCHES)\\n')[0]\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "681825c9-d00d-4483-9b56-c9dcccde85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '29', '', '', '12/19', '', '', '', '', '', '', '', '', '34', '', '', '', '', '', '-5', '', '', '', '', '', '', '', '2', '', '12/23', '', '', '', '', '', '', '', '\\nAVG.', 'MAXIMUM', '', '', '', '59.8', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '52.6', '', '', '', '', '7.2', '', '', '', '', '53.9', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nAVG.', 'MINIMUM', '', '', '', '37.9', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '33.3', '', '', '', '', '4.6', '', '', '', '', '36.5', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nMEAN', '', '', '', '', '', '', '', '', '', '', '', '48.8', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '43.0', '', '', '', '', '5.8', '', '', '', '', '45.2', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nDAYS', 'MAX', '>=', '90', '', '', '', '', '0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '0.0', '', '', '', '', '0.0', '', '', '', '', '', '', '', '0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nDAYS', 'MAX', '<=', '32', '', '', '', '', '0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '0.9', '', '', '', '-0.9', '', '', '', '', '', '', '', '1', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nDAYS', 'MIN', '<=', '32', '', '', '', '', '7', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '13.4', '', '', '', '-6.4', '', '', '', '', '', '', '12', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\nDAYS', 'MIN', '<=', '0', '', '', '', '', '', '0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '0.0', '', '', '', '', '0.0', '', '', '', '', '', '', '', '0', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '\\n']\n"
     ]
    }
   ],
   "source": [
    "temp_data = text.split('\\n................................................................\\nTEMPERATURE (F)\\n')[-1].split('\\nPRECIPITATION (INCHES)\\n')[0]\n",
    "high = temp_data.split('\\nHIGHEST')[-1].split(' ')\n",
    "low = temp_data.split('\\nLOWEST')[-1].split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbcd8b-d5d5-4910-8225-26471f3ae794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd85c6e-099e-494a-bb3a-a9b0d84006bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3512979-a064-4040-b53d-5ad55e57b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "\n",
    "    'mon'  : [calendar.month_name[i][:3].upper() for i in range(1,13)], # generate the abbreviated month names\n",
    "    'highs': [],\n",
    "    'high_dates': [], # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "    'lows': [],\n",
    "    'low_dates': []  # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f31eef15-1567-493c-b32a-00b731ceaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high data\n",
      "['77', '01/11', '50', '27', '72', '01/13']\n",
      "low data\n",
      "['25', '01/14', '31', '-6', '17', '01/22']\n",
      "\n",
      "\n",
      "high data\n",
      "['81', '02/28', '56', '25', '72', '02/11', '\\n', '02/17']\n",
      "low data\n",
      "['27', '02/18', '35', '-8', '23', '02/05', '\\n', '02/04', '\\n', '02/06', '\\n', '02/13']\n",
      "\n",
      "\n",
      "high data\n",
      "['83', '03/23', '64', '19', '82', '03/06']\n",
      "low data\n",
      "['26', '03/20', '43', '-17', '26', '03/12']\n",
      "\n",
      "\n",
      "high data\n",
      "['89', '04/04', '73', '16', '85', '04/24', '\\n', '04/29']\n",
      "low data\n",
      "['41', '04/24', '50', '-9', '33', '04/01']\n",
      "\n",
      "\n",
      "high data\n",
      "['87', '05/08', '76', '11', '91', '05/12']\n",
      "low data\n",
      "['43', '05/01', '56', '-13', '45', '05/04']\n",
      "\n",
      "\n",
      "high data\n",
      "['100', '06/29', '89', '11', '100', '06/22', '\\n', '06/30', '\\n', '06/25']\n",
      "low data\n",
      "['66', '06/13', '68', '-2', '61', '06/03']\n",
      "\n",
      "\n",
      "high data\n",
      "['102', '07/29', '93', '9', '103', '07/26']\n",
      "low data\n",
      "['67', '07/10', '72', '-5', '71', '07/15', '\\n', '07/11']\n",
      "\n",
      "\n",
      "high data\n",
      "['107', '08/26', '92', '15', '104', '08/15']\n",
      "low data\n",
      "['65', '08/17', '71', '-6', '67', '08/19', '\\n', '08/14']\n",
      "\n",
      "\n",
      "high data\n",
      "['102', '09/06', '85', '17', '101', '09/21']\n",
      "low data\n",
      "['59', '09/18', '64', '-5', '51', '09/29', '\\n', '09/30']\n",
      "\n",
      "\n",
      "high data\n",
      "['95', '10/01', '75', '20', '92', '10/15']\n",
      "low data\n",
      "['34', '10/31', '52', '-18', '33', '10/19']\n",
      "\n",
      "\n",
      "high data\n",
      "['83', '11/06', '62', '21', '83', '11/09', '\\n', '11/07']\n",
      "low data\n",
      "['29', '11/27', '42', '-13', '25', '11/21', '\\n', '11/17']\n",
      "\n",
      "\n",
      "high data\n",
      "['69', '12/01', '53', '16', '74', '12/29']\n",
      "low data\n",
      "['29', '12/19', '34', '-5', '2', '12/23']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mon': ['JAN',\n",
       "  'FEB',\n",
       "  'MAR',\n",
       "  'APR',\n",
       "  'MAY',\n",
       "  'JUN',\n",
       "  'JUL',\n",
       "  'AUG',\n",
       "  'SEP',\n",
       "  'OCT',\n",
       "  'NOV',\n",
       "  'DEC'],\n",
       " 'highs': ['77',\n",
       "  '81',\n",
       "  '83',\n",
       "  '89',\n",
       "  '87',\n",
       "  '100',\n",
       "  '102',\n",
       "  '107',\n",
       "  '102',\n",
       "  '95',\n",
       "  '83',\n",
       "  '69'],\n",
       " 'high_dates': [['01/11'],\n",
       "  ['02/28'],\n",
       "  ['03/23'],\n",
       "  ['04/04'],\n",
       "  ['05/08'],\n",
       "  ['06/29'],\n",
       "  ['07/29'],\n",
       "  ['08/26'],\n",
       "  ['09/06'],\n",
       "  ['10/01'],\n",
       "  ['11/06'],\n",
       "  ['12/01']],\n",
       " 'lows': ['25',\n",
       "  '27',\n",
       "  '26',\n",
       "  '41',\n",
       "  '43',\n",
       "  '66',\n",
       "  '67',\n",
       "  '65',\n",
       "  '59',\n",
       "  '34',\n",
       "  '29',\n",
       "  '29'],\n",
       " 'low_dates': [['01/14'],\n",
       "  ['02/18'],\n",
       "  ['03/20'],\n",
       "  ['04/24'],\n",
       "  ['05/01'],\n",
       "  ['06/13'],\n",
       "  ['07/10'],\n",
       "  ['08/17'],\n",
       "  ['09/18'],\n",
       "  ['10/31'],\n",
       "  ['11/27'],\n",
       "  ['12/19']]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_maxmin_data(high_data, low_data):\n",
    "\n",
    "    '''\n",
    "    Worker function to extract high and low data/dates from the CLM products.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # filter out the '' values inside the lists\n",
    "    high_data = list(filter(None, high_data))\n",
    "    low_data = list(filter(None, low_data))\n",
    "\n",
    "    print('high data')\n",
    "    print(high_data)\n",
    "    print('low data')\n",
    "    print(low_data)\n",
    "    print('\\n')\n",
    "\n",
    "    # now lets get some data\n",
    "    data_dict['highs'].append(high_data[0])\n",
    "    data_dict['lows'].append(low_data[0])\n",
    "\n",
    "    data_dict['high_dates'].append([high_data[1]])\n",
    "    data_dict['low_dates'].append([low_data[1]])\n",
    "\n",
    "\n",
    "# establish our main working dictionary\n",
    "data_dict = {\n",
    "\n",
    "    'mon'  : [calendar.month_name[i][:3].upper() for i in range(1,13)], # generate the abbreviated month names\n",
    "    'highs': [],\n",
    "    'high_dates': [], # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "    'lows': [],\n",
    "    'low_dates': []  # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "}\n",
    "\n",
    "# working directory, this wont exist in the final product (will poll from the IEM API)\n",
    "directory = 'D:/Climate/'\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    #print(file)\n",
    "    f = os.path.join(directory, file)\n",
    "    f = open(f,'r')\n",
    "    \n",
    "    text = f.readlines() # this extracts all the text data from each file\n",
    "\n",
    "    text = ''.join(text)\n",
    "    #print(text)\n",
    "\n",
    "    # here we are splitting the data to get to the monthly temp information\n",
    "    temp_data = text.split('\\n................................................................\\nTEMPERATURE (F)\\n')[-1].split('\\nPRECIPITATION (INCHES)\\n')[0]\n",
    "    \n",
    "    # splits to parse out the high and low temp data for the month\n",
    "    #print('high data')\n",
    "    high_data = temp_data.split('\\nHIGHEST')[-1].split('\\nLOWEST')[0].split(' ')\n",
    "    #print('low data\\n')\n",
    "    low_data = temp_data.split('\\nLOWEST')[-1].split('\\nAVG')[0].split(' ')\n",
    "    \n",
    "        \n",
    "        \n",
    "    get_maxmin_data(high_data, low_data)\n",
    "\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "18db749c-cd3f-4439-b570-cc03b897d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JAN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'FEB': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'MAR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'APR': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'MAY': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'JUN': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'JUL': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'AUG': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'SEP': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'OCT': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'NOV': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []},\n",
       " 'DEC': {'highs': [], 'high_dates': [], 'lows': [], 'low_dates': []}}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish our main working dictionary\n",
    "data_dict = {}\n",
    "\n",
    "for i in range(1,13):\n",
    "    _data_dict = {\n",
    "         f'{calendar.month_name[i][:3].upper()}' : {# generate the abbreviated month names\n",
    "        'highs': [],\n",
    "        'high_dates': [], # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "        'lows': [],\n",
    "        'low_dates': []  # these should still contain 12 items, but will be lists inside lists in case of multiple dates\n",
    "        }\n",
    "    }\n",
    "    data_dict.update(_data_dict)\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2516a7-f5c5-4434-8d70-fb6b32693066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af66f112-d1ee-4f75-8dbc-50d1cb388736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 \n",
      "CXUS54 KLZK 151933\n",
      "CLMLIT\n",
      "\n",
      "CLIMATE REPORT...UPDATED WITH SUPPLEMENTAL DATA \n",
      "NATIONAL WEATHER SERVICE LITTLE ROCK AR\n",
      "0135 PM CST MON JAN 15 2024\n",
      "\n",
      "...................................\n",
      "\n",
      "...THE LITTLE ROCK ADAMS FIELD CLIMATE SUMMARY FOR THE MONTH OF DECEMBER 2023...\n",
      "\n",
      "CLIMATE NORMAL PERIOD 1991 TO 2020\n",
      "CLIMATE RECORD PERIOD 1874 TO 2023\n",
      "\n",
      "WEATHER         OBSERVED          NORMAL  DEPART   LAST YEAR'S         \n",
      "                VALUE   DATE(S)   VALUE   FROM     VALUE DATE(S)       \n",
      "                                          NORMAL                       \n",
      "................................................................\n",
      "TEMPERATURE (F)\n",
      "RECORD\n",
      " HIGH             81   12/26/2015                                      \n",
      " LOW              -1   12/23/1989                                      \n",
      "                       12/24/1963                                      \n",
      "HIGHEST           69   12/01         53      16       74  12/29        \n",
      "LOWEST            29   12/19         34      -5        2  12/23        \n",
      "AVG. MAXIMUM    59.8               52.6     7.2     53.9               \n",
      "AVG. MINIMUM    37.9               33.3     4.6     36.5               \n",
      "MEAN            48.8               43.0     5.8     45.2               \n",
      "DAYS MAX >= 90     0                0.0     0.0        0               \n",
      "DAYS MAX <= 32     0                0.9    -0.9        1               \n",
      "DAYS MIN <= 32     7               13.4    -6.4       12               \n",
      "DAYS MIN <= 0      0                0.0     0.0        0               \n",
      "\n",
      "PRECIPITATION (INCHES)\n",
      "RECORD\n",
      " MAXIMUM       16.92   1884                                            \n",
      " MINIMUM        0.14   1889                                            \n",
      "TOTALS          1.40               5.08   -3.68     6.15               \n",
      "DAILY AVG.      0.05               0.16   -0.11     0.20               \n",
      "DAYS >= .01        5                9.5    -4.5       13               \n",
      "DAYS >= .10        3                                   8               \n",
      "DAYS >= .50        1                                   4               \n",
      "DAYS >= 1.00       0                1.5    -1.5        2               \n",
      "GREATEST\n",
      " 24 HR. TOTAL   2.21   11/30 TO 12/01                                  \n",
      " STORM TOTAL    0.79                                                   \n",
      " (MM/DD(HH))                                                           \n",
      "\n",
      "SNOWFALL (INCHES)\n",
      "RECORDS\n",
      " TOTAL          10.3   2012                                            \n",
      " 24 HR TOTAL    10.3   12/25/2012 TO 12/26/2012                        \n",
      " SNOW DEPTH       10   12/26/2012                                      \n",
      "TOTALS           0.0                0.6    -0.6      0.1               \n",
      " LIQUID EQUIV   0.00               0.02   -0.02     0.00               \n",
      "SINCE 7/1        0.0                0.6    -0.6       MM               \n",
      " LIQUID 7/1     0.00               0.00    0.00       MM               \n",
      "SNOWDEPTH AVG.     0                                                   \n",
      "DAYS >= TRACE      0                0.3    -0.3        2               \n",
      "DAYS >= 1.0        0                                   0               \n",
      "GREATEST\n",
      " SNOW DEPTH        0                                                   \n",
      " 24 HR TOTAL      MM                                  MM               \n",
      "\n",
      "DEGREE DAYS\n",
      "HEATING TOTAL    496                684    -188      611               \n",
      " SINCE 7/1       886               1264    -378       MM               \n",
      "COOLING TOTAL      0                  1      -1        3               \n",
      " SINCE 1/1      2695               1990     705       MM               \n",
      "\n",
      "FREEZE DATES\n",
      "RECORD\n",
      " EARLIEST     10/20/1989                                               \n",
      " LATEST       04/19/1983                                               \n",
      "EARLIEST                        11/01                                  \n",
      "LATEST                          03/20                                  \n",
      "................................................................\n",
      "\n",
      "WIND (MPH)\n",
      "AVERAGE WIND SPEED              6.5                                    \n",
      "HIGHEST WIND SPEED/DIRECTION    25/020    DATE  12/09                  \n",
      "HIGHEST GUST SPEED/DIRECTION    36/010    DATE  12/09                  \n",
      "\n",
      "SKY COVER\n",
      "POSSIBLE SUNSHINE (PERCENT)   MM                                       \n",
      "AVERAGE SKY COVER           0.48                                       \n",
      "NUMBER OF DAYS FAIR           11                                       \n",
      "NUMBER OF DAYS PC             10                                       \n",
      "NUMBER OF DAYS CLOUDY         10                                       \n",
      "\n",
      "\n",
      "WEATHER CONDITIONS. NUMBER OF DAYS WITH \n",
      "THUNDERSTORM              1     MIXED PRECIP               0          \n",
      "HEAVY RAIN                1     RAIN                       4           \n",
      "LIGHT RAIN                9     FREEZING RAIN              0          \n",
      "LT FREEZING RAIN          0     HAIL                       0         \n",
      "HEAVY SNOW                0     SLEET                      0         \n",
      "FOG                       9     FOG W/VIS <= 1/4 MILE      2           \n",
      "HAZE                      3                                            \n",
      "\n",
      "-  INDICATES NEGATIVE NUMBERS.\n",
      "R  INDICATES RECORD WAS SET OR TIED.\n",
      "MM INDICATES DATA IS MISSING.\n",
      "T  INDICATES TRACE AMOUNT.\n",
      "\n",
      "&&\n",
      "\n",
      "ï»¿...ADDITIONAL DATA FOR LITTLE ROCK ADAMS FIELD â€“ DECEMBER 2023...\n",
      "\n",
      ".MONTHLY AVERAGE... \n",
      "THE AVERAGE HIGH TEMPERATURE OF 59.8 (+7.2) WAS THE 5TH HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE AVERAGE LOW TEMPERATURE OF 37.9 (+4.6) WAS THE 33RD HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE AVERAGE MEAN TEMPERATURE OF 48.8 (+5.8) WAS THE 15TH HOTTEST AND \n",
      "WARMEST SINCE 2021.\n",
      "\n",
      "THE MONTHLY HIGH, LOW, AND MONTH AVERAGE TEMPERATURES WERE WELL \n",
      "ABOVE THE 30-YEAR CLIMATOLOGICAL AVERAGES BY AN AMOUNT OF 4 TO 7 \n",
      "DEGREES.\n",
      " \n",
      ".DAILY TEMPERATURES...\n",
      "DAILY TEMPERATURES WERE AVERAGE FOR 1 DAY.\n",
      "DAILY TEMPERATURES WERE ABOVE AVERAGE ON 27 DAYS.\n",
      "DAILY TEMPERATURES WERE BELOW AVERAGE ON 3 DAYS.\n",
      " \n",
      ".DAILY TEMPERATURE RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY TEMPERATURE RECORDS WERE TIED OR BROKEN. \n",
      "\n",
      ".MONTHLY RAINFALL...\n",
      "THE MONTHLY RAINFALL TOTAL OF 1.40 WAS TIED FOR THE 11TH DRIEST ON \n",
      "RECORD AND DRIEST SINCE 2005.THE MONTHLY RAINFALL WAS -3.68 BELOW \n",
      "AVERAGE FOR THE MONTH.\n",
      " \n",
      ".DAILY RAINFALL RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY RAINFALL RECORDS WERE TIED OR BROKEN. \n",
      "\n",
      ".MONTHLY SNOWFALL...\n",
      "NO MONTHLY SNOWFALL WAS RECORDED.\n",
      "THE MONTHLY SNOWFALL WAS -0.6 BELOW AVERAGE FOR THE MONTH.\n",
      " \n",
      ".DAILY SNOWFALL RECORDS TIED OR BROKEN DURING THE MONTH...\n",
      "NO DAILY SNOWFALL RECORDS WERE TIED OR BROKEN.\n",
      "\n",
      ".ADDITIONAL SIGNIFICANT EVENTS DURING THE MONTH...\n",
      "NO ADDITIONAL SIGNIFICANT EVENTS OCCURRED DURING THE MONTH.\n",
      "\n",
      "$$\n",
      "\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "feb6fee9-8281-49d0-8cad-9f146a5f3968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '69',\n",
       " '',\n",
       " '',\n",
       " '12/01',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '53',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '16',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '74',\n",
       " '',\n",
       " '12/29',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nLOWEST',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '29',\n",
       " '',\n",
       " '',\n",
       " '12/19',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '34',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '12/23',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nAVG.',\n",
       " 'MAXIMUM',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '59.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '52.6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '53.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nAVG.',\n",
       " 'MINIMUM',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '37.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '33.3',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '36.5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nMEAN',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '48.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '43.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '5.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '45.2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '>=',\n",
       " '90',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '<=',\n",
       " '32',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-0.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '32',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '13.4',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-6.4',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '12',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\n']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = high\n",
    "\n",
    "test = [x for x in test if not test == '']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "af882e41-cfec-4602-abfc-1b3780fb27fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['69',\n",
       " '12/01',\n",
       " '53',\n",
       " '16',\n",
       " '74',\n",
       " '12/29',\n",
       " '\\nLOWEST',\n",
       " '29',\n",
       " '12/19',\n",
       " '34',\n",
       " '-5',\n",
       " '2',\n",
       " '12/23',\n",
       " '\\nAVG.',\n",
       " 'MAXIMUM',\n",
       " '59.8',\n",
       " '52.6',\n",
       " '7.2',\n",
       " '53.9',\n",
       " '\\nAVG.',\n",
       " 'MINIMUM',\n",
       " '37.9',\n",
       " '33.3',\n",
       " '4.6',\n",
       " '36.5',\n",
       " '\\nMEAN',\n",
       " '48.8',\n",
       " '43.0',\n",
       " '5.8',\n",
       " '45.2',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '>=',\n",
       " '90',\n",
       " '0',\n",
       " '0.0',\n",
       " '0.0',\n",
       " '0',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '<=',\n",
       " '32',\n",
       " '0',\n",
       " '0.9',\n",
       " '-0.9',\n",
       " '1',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '32',\n",
       " '7',\n",
       " '13.4',\n",
       " '-6.4',\n",
       " '12',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '0',\n",
       " '0',\n",
       " '0.0',\n",
       " '0.0',\n",
       " '0',\n",
       " '\\n']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = list(filter(None, test))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "934f5590-af4e-44ea-8735-ab26ac58fd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6912/0153167412/29',\n",
       " 'LOWEST2912/1934-5212/23',\n",
       " 'AVG.MAXIMUM59.852.67.253.9',\n",
       " 'AVG.MINIMUM37.933.34.636.5',\n",
       " 'MEAN48.843.05.845.2',\n",
       " 'DAYSMAX>=9000.00.00',\n",
       " 'DAYSMAX<=3200.9-0.91',\n",
       " 'DAYSMIN<=32713.4-6.412',\n",
       " 'DAYSMIN<=000.00.00']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while (\"\" in test):\n",
    "   test.remove(\"\")\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fffee2-2a42-4bfe-9820-bde22b8cf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ccf4e1b7-a885-4d66-b47f-4732e4c452b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '69',\n",
       " '',\n",
       " '',\n",
       " '12/01',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '53',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '16',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '74',\n",
       " '',\n",
       " '12/29',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nLOWEST',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '29',\n",
       " '',\n",
       " '',\n",
       " '12/19',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '34',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '12/23',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nAVG.',\n",
       " 'MAXIMUM',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '59.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '52.6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '53.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nAVG.',\n",
       " 'MINIMUM',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '37.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '33.3',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4.6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '36.5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nMEAN',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '48.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '43.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '5.8',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '45.2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '>=',\n",
       " '90',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MAX',\n",
       " '<=',\n",
       " '32',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-0.9',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '32',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '13.4',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '-6.4',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '12',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\nDAYS',\n",
       " 'MIN',\n",
       " '<=',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0.0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\\n']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36c8eafa-f85d-4af5-9a8e-38ca62ec0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9985f23-48e7-499e-84b0-adf321505f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mon': ['jan',\n",
       "  'feb',\n",
       "  'mar',\n",
       "  'apr',\n",
       "  'may',\n",
       "  'jun',\n",
       "  'jul',\n",
       "  'aug',\n",
       "  'sep',\n",
       "  'oct',\n",
       "  'nov',\n",
       "  'dec'],\n",
       " 'highs': ['69']}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fcfd51f-a11a-46f3-a0ff-c360fbed93b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JAN',\n",
       " 'FEB',\n",
       " 'MAR',\n",
       " 'APR',\n",
       " 'MAY',\n",
       " 'JUN',\n",
       " 'JUL',\n",
       " 'AUG',\n",
       " 'SEP',\n",
       " 'OCT',\n",
       " 'NOV',\n",
       " 'DEC']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=[calendar.month_name[i][:3].upper() for i in range(1,13)]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9144744-79ca-46d0-809a-98b8ea38f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809784ae-044b-4aa5-9112-1fa2fc098bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
